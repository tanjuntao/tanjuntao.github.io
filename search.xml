<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux学习记录:ps命令以及和grep配合使用]]></title>
    <url>%2F2020%2F03%2F29%2FLinux%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95-ps%E5%91%BD%E4%BB%A4%E4%BB%A5%E5%8F%8A%E5%92%8Cgrep%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>ps</tag>
        <tag>grep</tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux学习记录：输入输出重定向与管道]]></title>
    <url>%2F2020%2F03%2F14%2FLinux%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%87%8D%E5%AE%9A%E5%90%91%E4%B8%8E%E7%AE%A1%E9%81%93%2F</url>
    <content type="text"><![CDATA[这篇文章来总结下 Linux 中的输入输出重定向功能，以及如何使用管道命令。 1. 背景需求有时候我们使用find 命令查找文件或目录时，会碰到 Permission denied 这样的错误输出信息。但是这些错误信息并不是我们想要的，我们只需要那些符合查询条件的输出，这种情况下该怎么办呢？输入输出重定向可以帮我们将错误信息和正确信息区分开来。 2. 输入输出重定向Linux 中的输入输出分为下面 3 种： 标准输入（standard input）：简称为 stdin，用数字 0 来做标记，一般用 键盘 作为我们的标准输入； 标准输出（standard output）：简称为 stdout，用数字 1 来做标记，一般用 屏幕 作为我们的标准输出； 标准错误输出（standard error output）：简称为 stderr，用数字 2 来标记，一般也用 屏幕 作为标准输出。 举几个例子： 当我们使用 cat 命令创建一个新文件 testfile 时，如下所示，我们的键盘就作为标准输入，将键入的内容输入到文件 testfile 中； 12345$cat testfile&gt; hello&gt; world &gt; // 按下 ctrl+D 结束此次输入$ 当我们使用 cat 命令输出文件内容时，是一种标准输出，文件的内容都将输出到屏幕上； 当我们使用 ll hello_world.c 命令来查看文件信息，但这个文件并不存在时，就会报错，错误信息会输出到屏幕上，是一种标准错误输出。 输入输出重定向的意思，是将原本从键盘获取的输入，重定向由某个文件输入；将原本输出到屏幕的信息，重定向出处到某个文件。 这里需要介绍几种输入输出符号所表示的含义： &lt; : 重定向标准输入，后面跟某个文件名，表示从该文件中获取输入； &gt; : 以覆盖的方式重定向标准输出，后面跟某个文件名，表示将信息输出到该文件中，会覆盖掉文件原有的内容； &gt;&gt; : 以追加的方式重定向标准输出，后面跟某个文件名，表示将信息输出到该文件中，但不会覆盖原有内容，而是追加在文件尾部； 2&gt; : 以覆盖的方式重定向标准错误输出，后面跟某个文件名，表示将错误信息输出到该文件中，会覆盖掉文件原有的内容； 2&gt;&gt; : 以追加的方式重定向标准错误输出，后面跟某个文件名，表示将错误信息输出到该文件中，但不会覆盖原有内容，而是追加在文件尾部。 讲了那么多还是觉得有点抽象，下面来看几个具体的例子。 之前的文章 ssh config 配置文件 中我们介绍了如何添加 isa_key.pub 到 authorized_keys 中，就用到了标准输出重定向，而且是以追加到文件尾部的方式添加的： 1cat isa_key.pub &gt;&gt; .ssh/authorized_keys 另一个例子。 我们使用 find 命令在 /home 目录下查找后缀名是 .c 的文件，我们想将查询到的结果保存到文件 result.txt 中，可以这么做： 1find /home -name "*.c" &gt;&gt; result.txt 这种情况下，屏幕上还是会将 Permission denied 的错误信息打印出来。如果想将这一部分错误信息保存到文件 error.txt 中，可以这么做： 1find /home -name "*.c" &gt;&gt; result.txt 2&gt;&gt; error.txt 那如果进一步，我们想要将正确的和错误的信息都同意保存到文件 result.txt 中呢？可以这么做： 1find /home -name "*.c" &gt;&gt; result.txt 2&gt;&gt;&amp;1 这个特殊语法记住就可以了。 最后，如果我们不想将正确信息和错误信息保存到文件，但又不希望错误信息输出到屏幕中干扰我们阅读，那可以使用 /dev/null。 我们可以将错误的信息都输出到 /dev/null，这个就相当于一个黑洞，输出给它的信息都会被其 “吃掉”： 1find /home -name "*.c" 2&gt; /dev/null 3. 管道命令管道命令的思想和输出重定向很像，即：将原本要输出到屏幕的内容导向到另外一个地方，输出重定向是导向到文件，管道命令是导向到另外一个命令，将上一个命令的输出，做为下一个命令的输入。 管道命令用符号 | 表示（shift + \），常见的形式如下： 1command1 | command2 | command3 即 command1 的标准输出作为 command2 的标准输入，然后 command2 的标准输出作为 command3 的标准输入。 *注：管道命令只能处理标准输出 stdout，并不能处理标准错误输出 stderr；并且，下一个命令必须能接收标准输入 stdin，像 ls、mv、cp 这类命令就不能作为管道命令。 使用 cut 和 grep 命令来演示下如何使用。 3.1 cut 命令本来我们使用 echo ${PATH} 的输出是这样的（每个环境变量之间用 : 间隔）： 1/home/ubuntu/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin 如果我们需要取出 第 4 个 环境变量，可以使用 cut 命令： 1echo $&#123;PATH&#125; | cut -d ':' -f 4 结果： 12ubuntu@VM-0-14-ubuntu:~/.ssh$ echo $&#123;PATH&#125; | cut -d ':' -f 4/usr/sbin cut 命令是一行一行的方式进行扫描的，其有两个重要参数： -d : 分隔符。如上例中用 : 作为一行字符串的分隔符； -f : 表示分隔后的字符串数组中，取第几个。注意这里下标是从 1 开始的。 3.2 grep 命令grep 命令也和 cut 命令一样，一行一行的分析字符串。本质上是一个搜索命令，当找到目标字符子串时，输出一整行。 下面看例子。 输入 last 命令可以查看最近的登录信息，结果如下： 12345678910ubuntu pts/0 223.104.36.169 Wed Mar 25 12:08 still logged inubuntu pts/0 223.104.35.123 Tue Mar 24 20:01 - 22:51 (02:50)ubuntu pts/0 117.136.101.13 Sun Mar 22 08:57 - 09:00 (00:02)ubuntu pts/0 117.136.117.165 Sat Mar 21 21:37 - 23:49 (02:11)ubuntu pts/2 117.136.101.154 Sun Mar 15 21:20 - 23:37 (02:17)ubuntu pts/0 117.136.101.154 Sun Mar 15 20:33 - 22:46 (02:12)ubuntu pts/3 223.104.18.117 Sat Mar 14 14:44 - 14:45 (00:00)ubuntu pts/0 223.104.18.117 Sat Mar 14 11:01 - 13:15 (02:13)...... 我们想找到登录用户是 reboot 的那些行，可以这么做： 1last | grep 'reboot' 结果： 123ubuntu@VM-0-14-ubuntu:~/.ssh$ last | grep 'reboot'reboot system boot 4.15.0-54-generi Fri Mar 6 08:49 still runningreboot system boot 4.15.0-54-generi Fri Mar 6 08:40 - 08:48 (00:08) 如上所述，能找到 2 行记录。如果进一步的，我们只想要用户名的信息（当然只是为了说明，实际肯定没人这么干），可以继续使用 cut 命令： 123ubuntu@VM-0-14-ubuntu:~$ last | grep 'reboot' | cut -d ' ' -f 1rebootreboot 4. References 《鸟哥的 Linux 私房菜》10.5 和 10.6 小节 https://einverne.github.io/post/2017/03/shell-io-redirect.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>标准输入</tag>
        <tag>标准输出</tag>
        <tag>管道</tag>
        <tag>重定向</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux学习记录：SUID 和 SGID 等特殊权限]]></title>
    <url>%2F2020%2F03%2F08%2FLinux%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%EF%BC%9ASUID-%E5%92%8C-SGID-%E7%AD%89%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[1. 引言在上一篇文章 Linux学习记录：chmod 修改权限 中，我们已经介绍了 Linux 中是如何控制文件以及目录的权限的。 这篇文章中我们再来介绍几种特殊的权限，即 SUID 、SGID 和 SBIT。 2. 相关背景从前面的介绍我们已经知道，使用 ll 命令来查看文件或者目录权限时，第一列一共有 10 个字符长度，我们从右往左编号，即 9876543210，其中： 9 共 1 位表示标识位：标识当前的文件类型。如 d 表示目录，- 表示普通文件； 876 共 3 位表示 属主 的权限； 543 共 3 位表示 组用户 的权限； 210 共 3 位表示 其他用户 的权限。 如果一个文件 test.txt 的权限为 -rwxrwxrwx，用二进制表示为 111-111-111，用八进制表示则为 777，所以我们经常会看到这种： 1chmod 777 test.txt 意思就是 属主 、组用户、其他用户 都能 read/write/execute 该文件。 其实 Linux 还有 3 个比特位来表示 SUID 、SGID 和 SBIT 等特殊权限。 3. 具体介绍Linux 表示文件或者目录的权限，总共用了 12 个比特位。其中最低的 9 位，即前面相关背景部分介绍的，用来表示 3 类不同用户的 read/write/execute 权限的。最高的 3 位，从高往低数，分别表示 SUID 权限、SGID 权限和 SBIT 权限。 举个例子： 1211 10 9 8 7 6 5 4 3 2 1 01 0 0 1 1 1 1 0 0 1 0 0 第一行表示二进制串的位置编号，从 0 开始。第二行表示是否具有对应位的权限，0 代表不具有，1 代表具有。 上述例子的意思是：该文件 属主 能够 read/write/execute，组用户 和 其他用户 只能够 read。同时该文件还具有 SUID 权限。 下面就来具体解释下什么是 SUID 、SGID 和 SBIT 权限。 3.1 SUID 权限SUID 表示 Set User IDentification 。只能用来控制：是否让某种文件具有 SUID 权限，不能用来控制目录。 当一个文件 example 被设置了 SUID 权限时，那么除了 属主 之外的所有用户，在执行 example 时，都将获得 属主 的权限。 举个例子。example 一开始的权限是： 1-rwxr-xr-x 我们给 example 设置 SUID 权限后，变成： 1-rwsr-xr-x 注意 属主 权限的 execute 位现在是 s 而不是 x，这是因为设置了 SUID 的原因。 此时，组用户 和 其他用户 在执行 example 程序时，就会获得 write 权限。而在设置 SUID 之前，这两类用户是不具备 write 权限的。 那么我们该怎么来设置这个 SUID 权限呢？还记得我们前面介绍的 12 位二进制位吗？我们只需要将最高位设置为 1，用八进制表示即 4755 。 原来我们是这么设置 example 的权限的： 1chmod 755 example 现在我们这么设置： 1chmod 4755 example 3.2 SGID 权限SGID 的道理和 SUID 相似，只不过 SGID 不仅可以用来控制文件权限，还能控制目录的权限。 还是使用之前的例子。我们的 example 文件一开始的权限是： 1-rwxr-xr-x 当我们给 example 设置 SGID 权限后，变成： 1-rwxr-sr-x 注意 组用户 权限的 execute 位现在是 s 而不是 x，这是因为设置了 SGID 的原因。 此时，组用户(不包括 其他用户) 在执行 example 程序时，就会获得 write 权限。而在设置 SGID 之前，组用户 是不具备 write 权限的。 设置 SGID 权限也很简单，只需要将次高位的二进制设置为 1 即可。所以此时 example 文件的权限值用八进制表示为 2755 。 所以可以这么设置： 1chmod 2755 example 那如果我们想要同时设置 SUID 和 SGID 权限该怎么办呢？想必你也很清楚了，只需要这么做： 1chmod 6755 example 3.2 SBIT 权限SBIT 只能用来控制目录的权限，不能用来控制文件。 如果一个目录被设置了 SBIT 权限，表示任何一个在此目录下可以新建文件的用户，该文件只有该用户自身、或者是 root用户 可以删除，除此之外的用户都无权删除。 举个例子，我们看 /tmp 目录的权限： 1ls -ld /tmp 结果： 12tan@DESKTOP-OPQIR8V:/mnt/c/Users/tanjuntao$ ll -ld /tmpdrwxrwxrwt 1 root root 512 Mar 8 13:52 /tmp/ 注意 其它用户 权限的 execute 位现在是 t 而不是 x，这是因为设置了 SBIT 的原因。 即所有用户都能在 /tmp 目录下新建文件或目录，但只有该用户自身或者 root用户 能够删除这些文件。 4. References https://blog.csdn.net/xiaocainiaoshangxiao/article/details/17378611 https://my.oschina.net/junn/blog/169381 https://www.tecmint.com/how-to-find-files-with-suid-and-sgid-permissions-in-linux/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>SUID</tag>
        <tag>SGID</tag>
        <tag>权限</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux学习记录：chmod 修改权限]]></title>
    <url>%2F2020%2F03%2F07%2FLinux%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%EF%BC%9Achmod-%E4%BF%AE%E6%94%B9%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[这篇文章记录下 Linux 中如何使用 chmod 命令修改文件以及目录的权限，也就是读/写/执行 的权限。 1. 背景需求有时候我们使用 scp 向服务器传输文件时，会提示说 permission denied 。这是因为我们对于需要上传到的目标目录没有 写 权限。此时需要修改目标目录的读写权限，使其对于所有用户都可写（当然这种做法不推荐），这样我们才能将文件传输上去。 另外一次经历，是之前需要将自己在 windows 中的 rsa keys 传到另外一台 Linux 机器上，这样能实现 rsa keys 的复用，也方便自己在另一台 Linux 机器上能正常向 github 提交代码。 但是，当我们使用 cp 命令将 windows 上的 id_rsa 和 id_rsa.pub 直接拷贝到 ~/.ssh 目录下，然后使用 ssh 时，会提示说 私钥的安全性不够，很容易被访问到。这时候就需要修改私钥文件和公钥文件的权限，以满足要求。 具体需要执行下面两条语句： 12chmod 600 id_rsachmod 644 id_rsa.pub 这两条命令有什么含义，继续往后看。 2. chmod 命令的使用Linux 中我们可以通过 ll 命令来查看文件和目录的权限。这里需要提一下，Linux 中并没有提供 ll 命令，这个命令是通过 alias 实现的。alias 的使用可以参考我上一篇博客：利用 alias 自定义一个删除备份命令 以我自己的服务器 home 目录为例，当我直接输入 ll 命令时，结果： 123456789101112131415161718ubuntu@VM-0-14-ubuntu:~$ lltotal 64drwxr-xr-x 7 ubuntu ubuntu 4096 Mar 7 10:30 ./drwxr-xr-x 3 root root 4096 Aug 8 2018 ../drwxrwxr-x 3 ubuntu ubuntu 4096 Mar 6 16:01 backup/-rw-rw-r-- 1 ubuntu ubuntu 233 Mar 6 16:01 .bash_aliases-rw------- 1 ubuntu ubuntu 3560 Mar 7 10:31 .bash_history-rw-r--r-- 1 ubuntu ubuntu 220 Aug 8 2018 .bash_logout-rw-r--r-- 1 ubuntu ubuntu 3773 May 29 2019 .bashrcdrwx------ 2 ubuntu ubuntu 4096 Aug 9 2018 .cache/drwx------ 3 ubuntu ubuntu 4096 Aug 9 2018 .gnupg/drwxr-xr-x 2 root root 4096 Mar 6 08:29 .pip/-rw-r--r-- 1 ubuntu ubuntu 807 Aug 8 2018 .profile-rw-r--r-- 1 root root 73 Mar 6 08:29 .pydistutils.cfgdrwx------ 2 ubuntu ubuntu 4096 Mar 6 10:39 .ssh/-rw-r--r-- 1 ubuntu ubuntu 0 Aug 9 2018 .sudo_as_admin_successful-rwxrwxrwx 1 ubuntu ubuntu 43 Mar 6 15:27 test_bash.sh*-rw------- 1 ubuntu ubuntu 8010 Mar 7 10:30 .viminfo 我们也可以单独查看某个文件或目录的权限： 1ll test_bash.sh 结果： 12ubuntu@VM-0-14-ubuntu:~$ ll test_bash.sh-rwxrwxrwx 1 ubuntu ubuntu 43 Mar 6 15:27 test_bash.sh* 输出的第一列 -rwxrwxrwx 就表示文件或目录的权限，下面详细解释。 第一位表示文件的类型： - ：表示普通文件； d ：表示目录，即 directory。 后面的 9 位按照 属主 / 组用户(group) / 其它用户 的顺序排列权限，每种用户的权限占据 3 位。 其中： r 表示可 read，用二进制表示为 100，用八进制表示为 4； w 表示可 write，用二进制表示为 010，用八进制表示为 2； x 表示可 execute，用二进制表示为 001，用八进制表示为 1。 如果某个位置为 - 表示该用户不具有此权限。以 drwxr-xr-x 为例： 第一个 rwx 表示 属主 具有 read/write/execute 权限； 第二个 r-x 表示 组用户 具有 read/execute 权限，但是没有 write 权限； 第三个 r-x 表示 其它用户 具有 read/execute 权限，但是没有 write 权限。 drwxr-xr-x 也可以用二进制来表示，即 111-101-101，转换为八进制即 755。755 和 drwxr-xr-x 表示同样的意思。 搞清楚了上面的解释，那么当我们需要将一个文件 test.txt 的权限设置成：属主可以 read/write，组用户和其他用户都只能 read 时（用二进制表示为 110-100-100），我们可以这么做： 1chmod 644 test.txt 最后，让我们再回过头来看背景需求部分介绍的 rsa keys 的权限问题： 12chmod 600 id_rsachmod 644 id_rsa.pub 第一行表示将私钥文件 id_rsa 设置为属主可 read/write，组用户和其他用户都不能 read/write/execute，这符合私钥文件的要求，即只有属主能访问到，属主之外的用户都无法访问； 第二行表示将公钥文件 id_rsa.pub 设置为属主可 read/write，组用户和其他用户都能 read。这也符合要求，即属主之外的用户可以利用属主的公钥来加密。 References https://blog.csdn.net/haydenwang8287/article/details/1753883 https://blog.csdn.net/pythonw/article/details/80263428]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>权限</tag>
        <tag>chmod</tag>
        <tag>777</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用 alias 自定义一个删除备份命令]]></title>
    <url>%2F2020%2F03%2F06%2F%E5%88%A9%E7%94%A8-alias-%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E5%88%A0%E9%99%A4%E5%A4%87%E4%BB%BD%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[这篇文章来记录下如何在 linux 中使用 alias 自定义一条删除备份命令。 1. 需求背景平时我们基本上都使用 rm 命令来删除不需要的文件，但是这个命令还是挺危险的，如果因为不小心删除了一些非常重要的文件，那基本上是恢复不会来了，因为我自己前些天就因为按 tab 的时候没注意补全的信息，直接就回车了……删除了一个很重要的代码源文件。 后面开始查找如何在 linux 下面回复删除的文件。尝试了网上介绍的一些方法，发现仍然不行，遂放弃…… 于是就想：linux 中能不能像 windows 下面一样，如果不是强制删除文件，那么这些被删除的文件首先是存放在 回收站 的，除非人为清空回收站，否则这些被“删除”的文件没有被真正删除。 于是开始搜寻资料，最后发现可以使用 alias 来实现这个需求。 2. 具体实现2.1 .bashrc 相关背景先简单介绍下 .bashrc 文件的相关背景。 .bashrc 存放在 home 目录下面。. 开头的文件表示为了防止文件被意外修改，而默认不显示。使用 ls 命令是不显示这个文件的，只有使用 ll 才看得到。 .bashrc 相当于配置文件，bash shell 每次启动时都会首先读取 .bashrc 文件，完成配置更新。 2.2 alias 相关背景这里先解释下，alias 的功能是提供命令简写，举个例子，在 .bashrc 文件中有下面几行代码： 123alias ll='ls -alF'alias la='ls -A'alias l='ls -CF' 这里的 ll 就是命令 ls -alF 的一个别名，起到的效果是一样的。（注意等号 = 两边不能有空格） 如果要查看系统中共有多少条简写命令，可以使用： 1alias -p 结果如下，这是我系统中目前所有的 alias： 123456789ubuntu@VM-0-14-ubuntu:~$ alias -palias alert='notify-send --urgency=low -i "$([ $? = 0 ] &amp;&amp; echo terminal || echo error)" "$(history|tail -n1|sed -e '\''s/^\s*[0-9]\+\s*//;s/[;&amp;|]\s*alert$//'\'')"'alias egrep='egrep --color=auto'alias fgrep='fgrep --color=auto'alias grep='grep --color=auto'alias l='ls -CF'alias la='ls -A'alias ll='ls -alF'alias ls='ls --color=auto' 2.3 将所有的自定义命令放在 .bash_aliases 文件里这里需要解释下为什么文件名为 .bash_aliases。用 vim 打开 .bashrc ，里面有一段这样的代码： 123if [ -f ~/.bash_aliases ]; then # 表示如果在 home 目录下面存在 .bash_aliases 文件 . ~/.bash_aliases # 那么执行这个文件。. 表示执行fi 一个比较推荐的方法是：将所有的自定义命令统一存放在 .bash_aliases 里。当然，如果直接把 alias 语句放在 .bashrc 里也能实现相应功能，只不过这种做法不推荐。 默认情况下，home 目录下是没有 .bash_aliases 文件的，我们需要自己用 touch 新建一个。 我们首先添加一个 ws 命令，方便我们在任何目录下，只需要输入 ws 就能回到 workspace 目录： 1alias ws='cd ~/workspace' 保存退出后 ws 命令还不能马上生效，我们还需要执行（先切换到 home 目录下）： 1source .bashrc 现在我们就能在任意目录下使用 ws 这个命令了。 有了上面的实践之后，我们已经知道 alias 的原理了。接下来我们新建一个 del 命令，是一个 “假删除” 的命令：即并不真正删除文件，而是将文件移动到一个特定位置。 vim 打开 .bash_aliases 文件，在文件尾部添加如下代码（所有的等号两边不能有空格）： 123456789function delete_and_back_file() &#123; date=`date +%Y%m%d` path=`pwd $1` output_path=~/backup/$date mkdir -p $&#123;output_path&#125;/ mv $path/$1 $&#123;output_path&#125;/$1&#125;alias del='delete_and_back_file' 下面解释下上面的代码。 因为我们想要实现的 del 命令其实是一个 移动文件 的命令，这就涉及到 源目录 和 目标目录，我们的 1del ./xxx.txt 等价于： 1mv ./xxx.txt &lt;目标目录&gt; 上述命令中，我们需要给定一个参数，即 xxx.txt ，表示想要删除的文件名。因为每次需要删除的文件都不同，等价于一个变量，我们不好直接使用 alias 来简写，这时候就需要使用函数。 代码第四行：output_path 表示我们想要把文件移动到哪个 目标目录 下，可以自定义； 代码第五行：mkdir -p 表示递归新建目录。举个例子，加入我们需要在 home 目录基础上新建 ~/dir1/dir2 目录： 如果直接使用 mkdir ~/dir1/dir2 是执行不了的； 这时候就需要使用 -p 参数，表示递归建立目录； 即首先新建 dir1 目录，然后在 dir1 下面再新建 dir2 目录。 代码第九行：将这个函数名赋值给我们的自定义命令 del （如果我们将自定义命令命名为 rm，那么会覆盖掉系统中的 rm 命令，这时候如果需要调用系统命令，需要使用 \ 进行转义，即输入 \rm ）。 最后，我们在执行： 1source .bashrc 至此，我们就可以在任意目录下面调用 del 命令了。它不会真正的删除文件，只是将文件移动 .bash_aliases 中指定的目录下。 3. Drawbacks目前的主要缺陷是 del 后只能跟一个文件名，无法一次性删除多个文件，无法使用 -r 删除一个文件夹。 不过这些实现起来应该不难，只需要修改 del_and_back_file 函数即可。等 shell 更加熟练后，可以来实现这个需求。 4. References https://askubuntu.com/questions/1414/how-to-create-a-permanent-alias https://www.jianshu.com/p/16c3e2305bd8 https://blog.csdn.net/chy555chy/article/details/88549924 https://blog.csdn.net/gloriaied/article/details/80669390]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>alias</tag>
        <tag>.bashrc</tag>
        <tag>.bash_aliases</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh config 配置文件]]></title>
    <url>%2F2020%2F03%2F06%2Fssh-config-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[这篇文章讲一下 ssh 中的 config 配置文件。 config 文件一般在 ~/.ssh/ 或者 C://Users//&lt;username&gt;//.ssh 目录下面，没有后缀名。如果在上述目录中找不到 config 文件，那么可以新建一个。 背景需求我们使用 ssh 登录服务器时，一般做法是： 1ssh example@example.com -p xxxx 然后再输入登录密码。 如果需要登录到不同的服务器，并且每个服务器的登录名、地址、端口号、登录密码都不同的话，那么记忆起来就会显得繁琐，那有没有一种办法可以不用输入密码登录，直接输入服务器的一个别名就可以登录的呢？答案是有的。 第一种比较容易想到的方法是建立一些脚本文件，在脚本里面将 ssh 登录需要的各种参数命令都预先写好，然后将该脚本加入到环境变量中，这样方便在任何地方都能调用。具体的实现方法可以 参考这篇 上面方法有一个缺陷就是，每次登录还是需要输入密码。 还有一种更加简单的方式，那就是使用 config 配置文件。 具体实现加入我们需要登录的服务器是 example.com， 登录用户名是 example，登录端口是 2222（ssh 默认登录端口是 22），那么我们可以在 config 文件中加入这些： 1234Host my_server HostName example.com User example Port 2222 几个字段的解释如下： Host：就是你设置的服务器别名，可以是任意自己方便记忆的名字； HostName： 服务器的实际地址，可以是 IP 地址，也可以是域名地址； User ：ssh 登录名； Port：端口号。如果是默认端口号 22，那此字段可以省略。 现在，你可以直接在终端中： 1ssh my_server 来登录服务器了。但是每次登陆还是需要输入密码。 那怎么配置来实现免密登录呢？答案是将本机的公钥存放到服务器上。 将本机中的 id_rsa.pub 公钥文件（windows 系统在 C://Users//&lt;username&gt;//.ssh 目录下，本地终端先切换到此目录下）传到服务器上任意位置，这里传到服务器 home 目录下： 1scp id_rsa.pub my_server:~ # 这里就可以直接使用 my_server 了 接着将 id_rsa.pub 中的公钥复制到服务器上的 authorized_keys 文件中。同样，如果服务器 ~/.ssh 目录下没有此文件，那么新建一个。 可以利用 cat 命令以及 Linux 中的输出重定向 &gt;&gt; 来实现。服务器首先切换到 home 目录下。 1cat id_rsa.pub &gt;&gt; .ssh/authorized_keys 最后还需要将 ssh 服务重启一下： 1/etc/init.d/ssh restart 回车后需要输入服务器的密码完成认证。 至此，就大功告成。现在只需要在本地终端中输入： 1ssh my_server 就能够免密登录到自己的服务器了。 References https://www.cnblogs.com/zhonghuasong/p/7236989.html https://www.cnblogs.com/piperck/p/6188984.html https://blog.csdn.net/ky1in93/article/details/83093981]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>ssh</tag>
        <tag>配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何格式化 64G 以上的 U盘/SD卡为 FAT32 文件系统格式]]></title>
    <url>%2F2020%2F03%2F05%2F%E5%A6%82%E4%BD%95%E6%A0%BC%E5%BC%8F%E5%8C%96-64G-%E4%BB%A5%E4%B8%8A%E7%9A%84-U%E7%9B%98-SD%E5%8D%A1%E4%B8%BA-FAT32-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[背景需求从网上购买的闪迪的 64G SD卡，准备插入小米摄像机里用来存储历史视频。但是插入之后，显示存储卡的格式不支持，SD卡是 NTFS 文件系统格式，但是小米摄像机需要 FAT32 格式。 遂准备 SD卡读卡器，插入 windows10 系统中，在资源管理器中通过鼠标右键选择“格式化”选项进行格式化。 但是 windows 系统中只能将 32G 以及 32G 容量以下的 U盘/SD卡 格式化为 FAT32 格式，但是对于 64G及以上的，无法完成格式化。于是只能寻求第三方软件。 解决方法发现一款很好的工具：DiskGenius 使用方法很简单，下载安装包，默认安装后，选择需要格式的盘符（选择插入的 SD卡），点击上方选项栏中的【格式化】按钮，选择 FAT32 格式就可以了。 Reference http://www.diskgenius.cn/download.php https://blog.csdn.net/b6_g9/article/details/52076285?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>格式化</tag>
        <tag>diskgenius</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux学习记录:查看文件和文件夹大小]]></title>
    <url>%2F2020%2F03%2F05%2FLinux%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95-%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E5%92%8C%E6%96%87%E4%BB%B6%E5%A4%B9%E5%A4%A7%E5%B0%8F%2F</url>
    <content type="text"><![CDATA[总结一下在 Linux 下面如何查看 文件 和 文件夹 的大小。为了方便理解和描述，我们的工作目录是 /datapool/workspace/tanjuntao/ ，所有的命令均在这个目录下面执行。 需求 1：如何查看 tanjuntao 下所有目录的大小，不显示子目录的大小命令： 1du -h --max-depth=1 . # . 就表示当前目录，-h 表示 -human-readable，以 M、G 等方式显示大小 结果： 123456789101112131415161718192021222324252627282930313233343536user@DataServer:/datapool/workspace/tanjuntao$ du -h --max-depth=1 .188K ./trash1.5G ./WaveMsNet449M ./FL-ESC105.7G ./FL-SVHN236M ./pytorch-playground1.7G ./ESC-50-master30M ./stat_learn_project648M ./pytorch-classification109M ./vanilla_machine_learning648M ./ml_fl172M ./Federated-Learning-PyTorch5.8G ./py3env211M ./data5.0M ./foolbox1.7G ./adversarial-robustness-toolbox43M ./archive2.4G ./WaveMsNet-master4.2G ./FL-Test66G ./FL-Cifar101.5G ./pytorch-svhn932M ./Environmental-Sound-Classification115M ./python254M ./CBIR384M ./pytorch-cifar1.1G ./FL-Influence189K ./federated-learning427G ./LearnML2.8G ./leaf4.0K ./.vscode8.0K ./test92K ./learn_git2.3G ./EvadeML-Zoo196M ./AdvBox114M ./Defensive-Distillation530G . 注意最后一行，表示当前 tanjuntao 目录的大小是 530G。 如果我们还需要进一步查看 ./FL-Cifar10 目录下那些目录比较大，可以继续使用： 1du -h --max-depth=1 ./FL-Cifar10 需求 2：如何只查看某个特定目录的大小比方说我们想要查看 tanjuntao 这个目录的总大小，我们可以使用需求1 中提到的命令，最后找输出中的最后一行，就可以得到 tanjuntao 目录的总大小。但我们还有更简单的方式。 命令： 1du -h --max-depth=0 . 结果： 12user@DataServer:/datapool/workspace/tanjuntao$ du -h --max-depth=0 .530G 也可以利用 -s 参数： 1du -sh . # -s 表示 -summarize 结果： 12user@DataServer:/datapool/workspace/tanjuntao$ du -sh .530G . 需求 3： 如何查看某个特定文件的大小如果我们需要查看 tanjuntao 目录下 master.zip 文件的大小，可以这么做。 命令： 1du -h ./master.zip 结果： 12user@DataServer:/datapool/workspace/tanjuntao$ du -h ./master.zip616M ./master.zip 除了使用 du 命令，还可以使用 ls 。 命令： 1ls -lh ./master.zip # -h 表示 -human-readable 结果： 12user@DataServer:/datapool/workspace/tanjuntao$ ls -lh ./master.zip-rw-rw-r-- 1 user user 616M Jan 31 20:31 ./master.zip 其中第五列就是文件大小。 需求 4： 如何查看当前目录下所有目录以及子目录的大小如果我们需要查看 tanjuntao 目录下面所有目录的大小，包括子目录，可以这么做。 命令： 1du -h . # 输出结果中只有目录，没有文件 需求 5： 如何查看某个目录下所有文件的大小假如我们需要查看 tanjuntao/data 目录下所有文件的大小（输出结果中没有目录，只有文件），可以这么做。 命令： 1du -ah ./data # 输出结果中只有文件，没有目录 结果： 12345678910111213141516171819user@DataServer:/datapool/workspace/tanjuntao$ du -ah ./data59K ./data/raw/train-labels-idx1-ubyte45M ./data/raw/train-images-idx3-ubyte9.5K ./data/raw/t10k-labels-idx1-ubyte7.5M ./data/raw/t10k-images-idx3-ubyte53M ./data/raw59K ./data/mnist/raw/train-labels-idx1-ubyte45M ./data/mnist/raw/train-images-idx3-ubyte9.5K ./data/mnist/raw/t10k-labels-idx1-ubyte7.5M ./data/mnist/raw/t10k-images-idx3-ubyte53M ./data/mnist/raw7.6M ./data/mnist/processed/test.pt46M ./data/mnist/processed/training.pt53M ./data/mnist/processed106M ./data/mnist7.6M ./data/processed/test.pt46M ./data/processed/training.pt53M ./data/processed211M ./data 需求 6：如何查看整个系统磁盘使用情况命令： 1df -h 结果： 1234567891011user@DataServer:/datapool/workspace/tanjuntao$ df -hFilesystem Size Used Avail Use% Mounted onudev 32G 0 32G 0% /devtmpfs 6.3G 562M 5.7G 9% /run/dev/sda2 438G 40G 376G 10% /tmpfs 32G 0 32G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 32G 0 32G 0% /sys/fs/cgroup/dev/sda1 511M 3.4M 508M 1% /boot/efinone 1.1P 32T 1.1P 3% /datapooltmpfs 6.3G 0 6.3G 0% /run/user/2001 References https://blog.csdn.net/ouyang_peng/article/details/10414499 https://blog.csdn.net/xiongyangg/article/details/54809810]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>du</tag>
        <tag>df</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 学习记录： wget 和 curl]]></title>
    <url>%2F2020%2F02%2F28%2FLinux-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%EF%BC%9A-wget-%E5%92%8C-curl%2F</url>
    <content type="text"><![CDATA[之前一直在用 wget 下载文件，最近又使用 curl 来提交 POST 请求，于是在这里将两者的主要用法以及区别总结下。 1. 二者比较 wget 主要用来下载文件，且速度较快，支持断点续传是其很大的优点； curl 也可以用来下载文件，但其功能不仅仅只有这些。curl 还可以用来向 web 提交表单信息。curl 可以理解成一个命令行版本的浏览器，只不过它对返回的 html 页面不做渲染。 2. 主要用法这里我们以下载 B 站的 一张壁纸 为例。 2.1 下载文件12345# wget 后直接跟文件地址wget https://i0.hdslb.com/bfs/album/323911edd18663c49ed1bdb7d3c02dfcac25c4ce.jpg# curl 需要使用参数，注意是大写字母 O，不是数字 0curl -O https://i0.hdslb.com/bfs/album/323911edd18663c49ed1bdb7d3c02dfcac25c4ce.jpg 2.2 下载文件然后重命名12345# wget 后需要跟参数，注意是大写字母 Owget -O wget_bizhi.jpg https://i0.hdslb.com/bfs/album/323911edd18663c49ed1bdb7d3c02dfcac25c4ce.jpg# curl 反过来了，跟的参数是小写字母 ocurl -o curl_bizhi.jpg https://i0.hdslb.com/bfs/album/323911edd18663c49ed1bdb7d3c02dfcac25c4ce.jpg 2.3 断点续传1234wget -c https://i0.hdslb.com/bfs/album/323911edd18663c49ed1bdb7d3c02dfcac25c4ce.jpg# 注意参数顺序是：-,大写字母C，空格，-，空格，-，大写字母Ocurl -C - -O https://i0.hdslb.com/bfs/album/323911edd18663c49ed1bdb7d3c02dfcac25c4ce.jpg 2.4 POST 提交请求curl 还能提交一个 POST 请求，下面是一个向第三方 API 提交请求的例子： 123456curl --location --request POST 'http://134.175.73.113:8080/member/login' \--header 'Content-Type: application/json' \--data-raw '&#123; "account": "15768092082", "password": "123456"&#125;' curl 命令还有很多其他的高级用法，具体可以参考下面这两篇博客： 11 cURL command usage with real-time example 15 Tips on how to use ‘curl’ command in Linux 3. References https://www.cnblogs.com/activecode/p/9446762.html https://blog.csdn.net/IT_hejinrong/article/details/79361095 https://www.zhihu.com/question/19598302]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>wget</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 中如何控制首页/归档页/tag页中显示的文章数]]></title>
    <url>%2F2020%2F02%2F28%2Fhexo-%E4%B8%AD%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6%E9%A6%96%E9%A1%B5-%E5%BD%92%E6%A1%A3%E9%A1%B5-tag%E9%A1%B5%E4%B8%AD%E6%98%BE%E7%A4%BA%E7%9A%84%E6%96%87%E7%AB%A0%E6%95%B0%2F</url>
    <content type="text"><![CDATA[因为此刻是在回忆之前所做的一些配置，所以修改之前的配置，具体值是多少，现在已经记不起来了，但还能记得清做了哪些实际修改。 1. 需求背景hexo 默认情况下，在 archive页 、tag页 是有分页的，也就是一个页面下只能显示有限篇文章，如果需要继续浏览其他的文章，就得进入下一个分页查看，有时候这对我们来说非常不方便，因为我们可能并不需要做分页，只希望一个页面下就能展示所有的文章。但是 hexo 中还没有地方能够做这个配置，需要单独装 插件 才可以。 首页 在默认情况下，也是多少篇文章就会分页，具体是多少已经不记得了，但是 首页 显示的文章数是可以在配置文件中设置的。 下面具体来介绍下该怎么设置每种页面下，显示的文章数。 2. 具体实现2.1 配置文件hexo 中的配置文件分为两种（我们用 ./ 来表示博客系统的根目录）： 系统配置文件：在 ./_config.yml 下，是用来对整个 hexo 博客系统进行配置的，如 博客title 、博客author 等等； 主题配置文件：我装的主题是 NexT，相应的主题文件就在 ./themes/next/_config.yml 下面，是用来对该主题进行配置的，如 导航栏 、页脚样式 等等。 我们的配置全程只需要用到 系统配置文件。 2.2 开始配置我们打开 系统配置文件，搜索关键字 per_page，看到对应的 index_generator 了吗，这一块就是用来设置 首页 文章该怎么显示的。per_page 后面就是 首页 显示的文章数量，这里我设置为 10 （注意英文冒号 : 后面有一个空格）: 1234index_generator: path: '' per_page: 10 order_by: -date 要修改 archive页 和 tag页 显示的文章数量，我们需要安装两个插件，前提是电脑上已经提前装好了 npm，下面命令可以在任意目录下面执行： 12npm install hexo-generator-archive --savenpm install hexo-generator-tag --save 安装完之后，我们需要在刚才的 index_generator 下面添加两个字段，具体如下： 123456archive_generator: # 0表示不分页，全部显示 per_page: 0 tag_generator: per_page: 0 同样，per_page 用于控制页面显示多少篇文章。0 表示不分页，所有文章全部显示。 3. References Hexo博客修改Archive页面显示文章数量 Hexo程序archive页面数量设置]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>配置</tag>
        <tag>hexo</tag>
        <tag>index_generator</tag>
        <tag>archive_generator</tag>
        <tag>tag_generator</tag>
        <tag>per_page</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在 Windows Terminal 中使用指定软件打开文件]]></title>
    <url>%2F2020%2F02%2F27%2F%E5%A6%82%E4%BD%95%E5%9C%A8-Windows-Terminal-%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AE%9A%E8%BD%AF%E4%BB%B6%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[背景我们知道在 Linux 系统下可以使用 vim 或者 vi 等命令，直接打开一个文本文件。但是 windows 下面没有 vim 和 vi，那么如何在终端中直接打开一个 markdown 文本文件呢？因为有时候有些文件目录很深，如果去资源管理器中寻找文件再打开，将会显得很繁琐，如果能在命令行中直接打开，将会提高效率很多。 需求尝试在 windows terminal 中实现类似下面的功能: 1typora xxx.md 可以在命令行中直接打开一个 markdown 文件，但是因为默认安装的 Typora 没有提供这个命令，所以我尝试将 Typora 安装目录中的 typora.exe 文件添加到 Path 环境变量中。 添加完后重启 windows terminal，重新输入上述命令，但是不能打开 xxx.md 文件，只是新建了一个空白的 markdown 文件。 解决方案使用 explorer.exe 。 前提是需要在系统中设置：默认使用 typora 来打开 *.md 的文件。 此时输入： 1explorer.exe xxx.md 就能顺利使用 typora 来打开 xxx.md 文件。 start 命令也能实现相同的效果： 1start xxx.md # 将会使用系统默认程序打开 xxx.md 文件 扩展如果想在 windows terminal 中打开资源管理器，该怎么办呢？ 只需要执行： 1explorer.exe . # '.'表示当前目录 start 命令也能实现相同功能： 1start . # 打开当前文件的资源管理器]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>typora</tag>
        <tag>markdown</tag>
        <tag>terminal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 学习记录: find 命令]]></title>
    <url>%2F2020%2F02%2F27%2FLinux-%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95-find-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[find 命令如何忽略大小写查找： 1find -iname "*visio*" 主要需要注意的地方是，find 命令没有 -i 参数，不能这么写： 1find -i -name "*visio*" 这样写是错误的，参考这篇文章； ​ https://blog.csdn.net/yanlaifan/article/details/52797155 Referenceshttps://www.cnblogs.com/chyingp/p/linux-command-find.html https://blog.csdn.net/wzzfeitian/article/details/40985549]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>find</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matlab里面利用classify函数做多类别线性判别分析]]></title>
    <url>%2F2019%2F12%2F11%2Fmatlab%E9%87%8C%E9%9D%A2%E5%88%A9%E7%94%A8classify%E5%87%BD%E6%95%B0%E5%81%9A%E5%A4%9A%E7%B1%BB%E5%88%AB%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记：A survey on Adversarial Machine Learning]]></title>
    <url>%2F2019%2F11%2F24%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9AA-survey-on-Adversarial-Machine-Learning%2F</url>
    <content type="text"><![CDATA[这篇简短的综述论文主要介绍了什么是Adversarial Machine Learning，列出了AML的几种常见分类。 IntroductionDefinition of adversarial machine learning machine learning in the presence of an adversary. All kinds of attacks can be categorized in three main types: poisoning attacks: trying to poison the training of test dat detection attacks: with the objective of evading detection model extraction attacks: with the objective of replicating the model 当然，这三种分类方法只是作何自己做的一个分类，实际上还可以有不同的分类方法，需要做的就是理解每一种分分类的划分依据是什么就可以了，不需要刻意去记住有那几种分类。 当然，还有一种分类是将攻击者和防御者建模成一个博弈问题。 It is worth to mention another much different aspect of research in adversarial machine learning which models the model-attacker worlds as a game and defines different moves for each side of the game.By such definition, a min-max algorithm can be used to determine best moves for each side and fide possible equilibriums of the game. Taxonomy这一小节列举出了目前在AML领域中几种常见的攻击方法。 A. Model Extraction Attacks 这种攻击方法一般在machine learning as a service的场景中。即云服务商只会给用户提供一个查询的API接口，但是每次查询是需要收费的。 这时候攻击者就希望能不能找到一个和目标模型表现近似的模型，从而避免向云服务商付费。 这种攻击可以大致分为下面3类： eqution-solving model extraction attacks在逻辑回归等简单模型中适用，原理主要是解方程组。 path finding attacks一般用在决策树模型中。 membership queries attacks判定一个给定的数据点事会否在原始数据集中。 B. Adversarial Examples 这个不需要过多解释了，现在的文章实在是太多了。 需要介绍的是在论文[1]中，作者提出了既能够欺骗人眼也能够欺骗机器的对抗样本。 对抗样本目前最需要解决的问题是防御问题，尤其时针对迁移性攻击的防御。 C. Data Poisoning Attacks 这种攻击适用于攻击者不能直接接触到训练数据，但训练过程是online training or adaptive training，即训练过程中需要不断加入新的训练数据。 这种攻击在SVM中很容易成功，因为svm做分类最主要就是support vectors在起作用。 D. Model Evasion Attacks 这种攻击和对抗样本攻击很像，是在模型做inference阶段的攻击。但是因为做spam detection or malware detection在机器学习中很重要，所以这种攻击就被单独拎出来了。 Conclusion 这篇文章中没有介绍道data inversion attack，即能够推导出原始训练数据近似的攻击。 AML的防御还是一个需要不断深入研究的领域。 参考[1] Elsayed, G.F., Shankar, S., Cheung, B.Papernot, N., Kurakin, A., Goodfellow, I. and Sohl-Dickstein, J., 2018. Adversarial Examples that Fool both Human and Computer Vision. arXiv preprint arXiv:1802.08195]]></content>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记：Federated Learning:Challenges, Methods and Future Directions]]></title>
    <url>%2F2019%2F11%2F23%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9AFederated-Learning-Challenges-Methods-and-Future-Directions%2F</url>
    <content type="text"><![CDATA[这篇博客简单总结一下这篇2019年8月份的综述文章。 这篇综述论文最主要的贡献在于阐述了当前研究情况下 federated learning 面临的主要问题，以及为了一下可以值得期望的研究方向。 可是就现阶段的研究而言，真的还有很多很多问题需要解决，联邦学习现在就是愿景非常美好，能够利用到不同device上面的额数据做一些训练任务，但是想真正的实现一个物理系统还有很多很多的工作需要做。 目前存在的4个主要问题如下： 通信开销太大 不同的device系统是异质的 不同device上面的数据也是异质的 联邦学习中的安全和隐私问题]]></content>
  </entry>
  <entry>
    <title><![CDATA[下载网络视频]]></title>
    <url>%2F2019%2F11%2F17%2F%E4%B8%8B%E8%BD%BD%E7%BD%91%E7%BB%9C%E8%A7%86%E9%A2%91%2F</url>
    <content type="text"><![CDATA[这篇文章介绍几种下载网页视频的方法。 方法1：第三方下载工具you-getyou-get是一个第三方的Python包，用户只需要安装这个包，然后就可以直接在命令行中下载视频，非常便捷。 step1没有安装Python3的需要先在电脑上安装Python3。接着使用pip3命令安装you-get。 1pip3 install --upgrade you-get # 确保安装最新版本 step2打开命令行，切换到想要保存视频文件的目录中，在浏览器地址栏中拷贝视频的播放地址，接着输入命令 1you-get &lt;视频地址&gt; 这种方式下载默认的视频格式文件，如果想要下载不同格式、不同清晰度的视频文件，可以加上-i参数： 1you-get -i &lt;视频地址&gt; 观察控制台的输出，然后选择自己想要下载的格式文件对应额下载命令，再重新执行一遍you-get命令，此时不用再带上-i命令： 1you-get &lt;每种格式文件对应的下载参数&gt; &lt;视频地址&gt; you-get目前支持很多网站的下载，如youtube bilibili 优酷 腾讯视频 等等。 方法2：直接在网页中找到视频文件原地址这种方式能成功的前提是网站的开发者并没有对视频文件做很好的保护，因为一般的大厂为了防止视频被下载，都会对视频文件的地址做保护。 下面介绍这种简单的下载方式。 在视频对应网页中右键检查或者直接F12打开网页调试页面。 点击调试面板最左上角的箭头，然后将鼠标移到网页中，点击视频文件所在的区域，然后就能在element中找到对应的video标签，src属性中地址就是视频文件的原地址了，一般是.mp4格式的。 在新标签中打开地址，在新标签中直接将视频另存为就能下载了。 方法3：使用插件+下载工具下载M3u8格式视频文件前面说了，一般的网站都会对视频源文件做保护，不能直接找到文件的原地址。常见的做法就是修改video标签的src属性为blob:https://xxxxx，这时候如果在新标签中打开这个地址，什么东西都找不到。 那么这种情况下怎么下载到原视频文件呢？ 这篇文章 中详细分析了blog:http的原理：网页中的视频文件被切分为了一个个小的ts格式的视频片段，这么做的原因，一方面是方便无缝切换视频清晰，另一方面是为了防止视频被下载。 但是尽管找到了ts格式的视频片段，但是也不能一个个的下载下来啊，太繁琐了。 于是有人做了Meu8这种受保护的视频格式文件的下载工具，具体可以follow这篇文章 参考 https://blog.csdn.net/Bumphy/article/details/82865889 https://blog.csdn.net/xingyun89114/article/details/80699527 https://blog.csdn.net/Angry_Mills/article/details/82705595]]></content>
  </entry>
  <entry>
    <title><![CDATA[信息熵]]></title>
    <url>%2F2019%2F11%2F11%2F%E4%BF%A1%E6%81%AF%E7%86%B5%2F</url>
    <content type="text"><![CDATA[这篇文章简单地总结一下信息熵。 概率和编码长度首先假设我们有离散型随机变量 X，X 总共有n个取值，每种取值的概率为p(x)。 假如X有4种可能的取值，每种取值的概率都相同，那么我们需要用2个二进制位来编码每种可能的取值。相应的，如果X有16个取值，那么需要用4个二进制位来编码。 但是如果每种取值发生的概率并不是相同的呢？例如，其中某个取值出现的概率明显要高于其他取值，如果这时候还是用相同的编码长度来编码每种可能的取值，就会造成一种浪费。一个直觉的方法是将概率大的取值分配较短的编码，概率小的取值分配稍微长的编码长度，这样使得整体的编码长度达到最短。 香农提出公式：如果概率为p(x)，那么所需要的编码长度为 那么对于整个概率分布，平均编码长度（每种概率对应的编码长度加权求和）为 上面的公式就是信息熵 。 信息熵的含义从上面的讨论中我们知道了：信息熵其实就等于平均编码长度。 如果熵越大，那么平均编码长度越大，能表示的可能性就越多，不确定性就越大，信息量就越大。（想想，如果平均编码长度为1，那么只能表示两种可能，这时候所能包含的信息就很少。） 对应到随机变量的概率分布上，如果概率分布越分散（极端情况下，均匀分布），那么表明这个随机变量的不确定性越高，平均编码长度越长，信息熵越大，包含的信息量越大。 同物理学中的熵做类比：物理学中，熵越大，表明越无序，对应到信息学中，表明可能性越多，包含的信息量越多。 what to take away 信息熵等于平均编码长度 信息熵越大，包含的信息量越大 均匀分布概率最分散，不确定性最大，信息熵最大。 参考 http://www.ruanyifeng.com/blog/2019/08/information-theory.html 信息熵、交叉熵、相对熵（KL散度）下面来叙述这3种常用熵的概念以及他们之间的联系。 从上面的讨论中我们知道：信息熵（也称为香农熵）对应着一种最优的编码方式，即找不到更短的平均编码长度了。 信息熵的公式实际上是在求1/log(p(x))的数学期望。 假如p(x)对应真实的概率分布，但在实际应用场景中，我们往往不知道真实分布，我们只能得到一个估计的概率分布q(x)，这时候，我们用q(x)来编码p(x)，即将原来每个p(x)对应的编码长度1/log(p(x))替换成1/log(q(x))，然后我们再计算这种编码方式对应的平均编码长度： 这就是交叉熵公式。 重点：当使用q(x)去编码p(x)时，得到的平均编码长度只会大于等于p(x)的香农熵（p(x)的最短编码长度）。等号成立的条件是q(x)完全等于p(x)，如果q(x)和p(x)之间的差别越大，那么得到的编码长度差别也就越大。 从上面的讨论可以知道，使用q(x)编码p(x)，得到的编码长度总是会比最短的编码长度大，那么多出来的这部分，我们定义为相对熵，也就是KL散度。 这里换一种公式来表达信息熵、交叉熵和KL散度……(因为hexo中不支持latex，我只能自己到处找别人写的公式….) 香农熵 交叉熵 相对熵 用一张图来表示这3者之间的关系如下： 上图中，第一行表示香农熵，第二行表示交叉熵，第三行表示KL散度。所谓的KL散度，其实就是交叉熵和香农熵之间的差值，并且永远取非负值。 当交叉熵和香农熵完全相同时（即估计得到的q(x)完全等于p(x))，这时计算得到的相对熵为0. 相对熵有下面几条性质： 如果两个函数f(x)和g(x)完全相同，那么计算两者之间的KL散度为0。两个函数之间的差异越大，那么KL散度越大。（这里f(x)和g(x)分别对应p(x)和q(x)) 相对熵可以用来度量两个概率分部之间的相似度，如果相对熵越小，那么说明两个概率分布越接近。 相对熵公式不对称，不具备交换律。即D(p, q)≠D(q, p)。 参考 https://www.zhihu.com/question/41252833/answer/140950659 https://www.zhihu.com/question/41252833/answer/141598211 （这篇文章后面关于KL散度的公式有错误，前面部分解释的还是很清楚的）https://blog.csdn.net/haolexiao/article/details/70142571]]></content>
  </entry>
  <entry>
    <title><![CDATA[关于贝叶斯公式的几种理解]]></title>
    <url>%2F2019%2F10%2F07%2F%E5%85%B3%E4%BA%8E%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F%E7%9A%84%E5%87%A0%E7%A7%8D%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记：Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks]]></title>
    <url>%2F2019%2F07%2F30%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9ADistillation-as-a-Defense-to-Adversarial-Perturbations-against-Deep-Neural-Networks%2F</url>
    <content type="text"><![CDATA[总览这篇文章发表在 S&amp;P 2016 上，是对抗样本领域中较早的一种系统性的防御方法，即defensive distillation(防御蒸馏)。因为先前的防御方法大多是经验性的，如对抗训练等等，都是从结果上证明了其防御有效，但没有从原理层次详细的分析防御之所以成功的原因。在本文中，作者观察在两个简单的识别MNIST和CIFAR10的模型上的实验结果，证实了defensive distillation方法的有效性，但这个方法在后来的文章中，也就是S&amp;P 2017 CW attack，被证实是无效的防御。]]></content>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记：DeepFool: a simple and accurate method to fool neural networks]]></title>
    <url>%2F2019%2F07%2F27%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9ADeepFool-a-simple-and-accurate-method-to-fool-neural-networks%2F</url>
    <content type="text"><![CDATA[寻找对抗样本的过程就是最优化下面的目标函数： 其中k表示分类器，r表示添加的扰动，delta文中表示的含义是分类器在x这个样本点处的robustness，其实就是扰动的L-2 norm。 分类器在整个数据集上的robustness计算公式如下： 从公式中可以看出，如果添加的扰动越小，计算到的ro值就越小，相应的根据文中的定义，分类器的robustness就越好。 本文中的主要贡献： 提出了一种新的计算对抗样本的方法DeepFool 从实验中验证了：新的攻击算法所添加的扰动更小，同时计算对抗样本所消耗的时间更少 实验中说明了：如果使用不恰当的算法（FGSM算法）来验证分类器的鲁棒性，那么很可能会过分的评估分类器的robustness。 攻击算法细节 二元分类 and 线性分类器 这是最简单的一种情况。我们有一个线性分类器，那么可以得到一个超平面将两个类别却分开来。 现在X属于其中一个类别，也就是在直线（或者超平面）的一侧，想要添加扰动使分类器将其分类为另一个类别，那么只需要将X更新到直线（或者超平面）另外一侧就可以了。 现在优化算法的约束条件是最小扰动，那么就只需要找到X到直线（超平面）的最短距离，使X加上这个距离后转换到直线另外一侧，那么就算是找到了对抗样本，同时也就找到了最小的扰动r(投影距离)。 这时候处理起来就很简单了，只需要使用一次距离公式即可： 分类器： 投影距离： 二元分类 and 非线性分类器 现在考虑一种更为普遍的setting。分类器的决策边界是非线性的。 这种情况等价于：寻找X到曲线的最短距离，然后将X加上这个最短距离，即可导致X转移到决策边界的另外一侧，从而被错误分类。 但是直接找这个投影点是不好找的。我们需要用到一种迭代的算法。下面简单描叙一下如何寻找一个点到一个曲线（或者是高维空间中的曲面）的最短距离。 12345678假设当前是第 i 次迭代我们在Xi这点对分类器使用一阶泰勒展开，我们将会得到一条直线（或者一个超平面）将Xi投影到这条直线上，我们找到了下一次迭代的X(i+1)，同时我们将这次迭代添加的扰动向量记为ri接着我们再在X(i+1)这点使用同样的方法，寻找下一次迭代的点X(i+2)，同时计算r(i+1)我们的算法一直迭代，知道找到的X落在分类器的决策边界上，算法终止。输出：将每一次迭代过程中产生的ri（是一个向量）全部累计起来（向量加法），得到最终的扰动r。 注：最后找到的扰动只能保证我们能将X改变到决策边界上，所以我们还需要在r的基础上乘上一个微小的系数，保证能越过决策边界。 多元分类 and 线性分类器 现在考虑多元分类情况下如何产生对抗样本，首先还是从简单的线性分类器开始考虑。 多元分类情形下，W是一个矩阵，每一行对应着其中一个类别的权重，通过W * X + b，我们最后得到的是一个score value，是一个向量，其中每一维代表每一个类别的评分。最后分类的标准就是找评分值最大的那个类别。所以我们寻找对抗样本，只需要找到一个类别k，使这个类别的评分值比X原来类别的评分值高，那么就可以达到对抗样本攻击的目的。 形式化的描述： 现在我们定义另外一个函数 因为每一个F_k(x)都是线性的，所以这个函数也是线性的，所以存在一个超平面。超平面的一侧函数值大于0，另外一侧小于0. 所以我们只需要添加扰动使这个函数值符号改变，那么我们就找到了一种产生对抗样本的方法。 因为假如现在的样本点X0（正确类别是4，这样说明了上面公式被减掉的那一项是F4(x))，带到函数中值小于0，表面当前类别4的评分值大于第k类的评分值。但是如果现在上述函数的函数值变为正号，说明第k类的评分值大于第4类，所以分类器这时候已经错误分类为第k类了，那么添加的扰动就是X0到这个函数的超平面的投影距离。 但是这个距离可能不是最小的，所以我们需要遍历所有类别k，找到最小的那个投影距离作为最后的扰动距离。 寻找这个类别k的公式 最后的最小扰动公式 多元分类 and 非线性分类器 同前面二元分类问题相似，我们使用的仍然是一阶泰勒展开的思路。 前面的公式是F_k(x) - F_4(x) = 0，现在这两个函数都是非线性函数，我们在Xi这点分别使用一阶泰勒展开，可以得到下面公式： 这个公式表示的是被分类器分类为正确类别的空间。我们找投影点的思路和前面二元分类相似，也是一个不断迭代的过程。 123我们在迭代的每一步都会使用一阶泰勒展开，将非线性的函数转为线性函数然后将Xi投影到这个线性函数所决定的超平面上，得到X(i+1)，同时计算投影距离r(i)然后不断这样一个泰勒展开-&gt;投影-&gt;泰勒展开-&gt;投影的过程，知道最后上述公式的函数值符号发生变化 当然，为了找到最小的扰动，我们需要针对所有的类别，都运用上面的算法，最后取扰动最小的那个。 实验结果 从图中可以看出 DeepFool所添加的扰动较[4][FGSM]和[18][L-BFGS]都要小（ro值越小，表明添加的扰动越小，参见ro的定义函数） DeepFool产生对抗样本的时间很短 上图是模型多迭代训练5个epoch，模型的鲁棒性的变化情况，可以看出： 如果使用原来的干净样本，模型鲁棒性基本没有变化 如果使用DeepFool产生的对抗样本（后5个epoch都是在这对抗样本上训练的），那么模型在1个epoch后的鲁棒性就大大提升 使用FGSM产生的对抗样本做训练，模型的鲁棒性反而会下降！！！ 然后作者们对这个奇怪的现象又做了另外一个实验。 他们将Deepfool产生的扰动放大，然后再使模型在这个放大的样本上训练，看训练后模型的鲁棒性怎么变化，结果如下图 如果只是deepfool产生的对抗样本，那么可以增加模型的鲁棒性；但是如果这个扰动太大了，反而会使模型鲁棒性降低，这就说明了FGSM算法产生的扰动很大，不是最小的扰动 然后作者们还做了一个实验，说明使用正确的方法（扰动更小的攻击方法）更能说明模型的鲁棒性，而使用那些扰动大的方法来评估模型的鲁棒性，往往会过分评估 作者首先是使用FGSM产生对抗样本，然后在这个样本上多训练了5个epoch。接着使用Deepfool在新的模型（更加的鲁棒）上产生对抗样本，计算ro的值，如蓝线所示；同时使用FGSM再重新生成对抗样本，同样也计算ro值，如红色点线所示。可以看到，后者明显过分估计了模型的鲁棒性，实际上行模型并没有其估计的那么鲁棒。]]></content>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记：Explaining and Harnessing Adversarial Examples]]></title>
    <url>%2F2019%2F07%2F15%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9AExplaining-and-Harnessing-Adversarial-Examples%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[论文阅读笔记：Intriguing Properties of Neural Network]]></title>
    <url>%2F2019%2F07%2F10%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9AIntriguing-Properties-of-Neural-Network%2F</url>
    <content type="text"><![CDATA[对抗样本（adversarial examples）的开山之作。 文中主要提到了神经网络两个比较奇怪的性质： 神经网络中携带语义信息的不是某单个神经元，而是整个网络所表示的空间。 给样本添加一些轻微的扰动，会导致神经网络模型错误分类，这些样本就称为对抗样本。 这里对第一个性质做简单的说明。 首先，作者们通过观察某个隐层中某个特定神经元对什么样的输入图片会产生最大的激活值，以此来确定这个神经元对什么样的特征是最敏感的，从而确定这个神经元包含什么样的语义信息。这个想法是可行的并且前面（2014年之前）已经有这方面的研究了。实验结果就发现：单个神经元确实能够表示某种语义信息。接着作者们又做了另外一个实验：选择隐层所表示的空间中的一个随机方向（就是基向量的随机线性组合，是隐层中单个神经元所无法表示的方向），然后用同样的方法使其激活值最大。实验结果发现，同单个神经元一样，这个随机的方向也能表示某种确切的语义信息，从而说明了这个随机方向也可以表示某种特征。 所以最后得到的结论就是：神经网络某个隐藏层中携带语义信息的并不是单个神经元，而是这个隐层所表示的整个空间。 文中提出来的几个假设： it is assumend that is possible for the output unit to assign non-significant(and, presumaby, non-epsilon)probabilities to regions of the input space that contain no training examples in their vicinity. the adversarial examples represent low-probability(high-dimensional)”pockets” in the manifold, which are hard to efficiently find by simply randomly sampling the input around a given example. 那么作者们是如何找到对抗样本的呢？ 寻找对抗样本的过程，其实是一个不断优化的过程：一方面我们希望添加的扰动尽可能小，因为如果是较大的扰动，任何state-of-the-art的模型都会错误分类，就算是人眼也可能识别不了，这和对抗样本问题的研究初衷不一样，我们想知道的是为什么神经网络在面对这些人眼不可分辨的图片时，会给出巨大的错误结果。另一方面，我们希望对抗样本能被错误分类到另一个其它类别，从损失函数的角度看，就是想让其越大越好，于是作者们给出了下面的优化目标函数： 其中x是原始图片，r是添加的扰动，f是分类器，l是目标类别（同x正确的类别不同）。我们希望r越小越好，同时使对抗样本x + r被错误分类到一个指定类别l下，同时还需要生成的x + r的值在[0,1]之间（保证是一张合法的图片）。 直接解这个问题不容易，因此作者转换了一种思路，从损失函数的角度找最优的r: 简单看看损失函数：一方面我们需要r的某种范式越小越好，另一方面我们希望loss(x+r, l)越小越好，因为这样表明x+r分类成类别l的概率越大。所以我们的目标是最小化上述公式，用到的方法是box-constrained L-BFGS. 最后，作者们通过实验发现了几个重要的现象： 对于论文中提到的所有网络结构（non-convolutional network, AlexNet, QuocNet），都能用上述方法生成对抗样本； 对抗样本具有跨模型的泛化能力：在A模型上产生的对抗样本，有很大一部分在B模型（和A模型结构相同，超参数不同）上也有效（也能是B模型错误分类） 对抗样本具有跨数据集的泛化能力：在D1数据集训练得到的模型上产生的对抗样本，在D2数据集训练得到的模型上也有效，D1和D2属于不同的子集，两个模型是结构完全不同的模型。]]></content>
  </entry>
  <entry>
    <title><![CDATA[统计学习方法：感知机]]></title>
    <url>%2F2019%2F07%2F09%2F%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%EF%BC%9A%E6%84%9F%E7%9F%A5%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[注：代码和运行结果都是从jupyter notebook中导出的 导入所需要的第三方库12345import pandas as pdimport numpy as npfrom sklearn.datasets import load_irisimport matplotlib.pyplot as plt%matplotlib inline 导入数据（iris数据集是sklearn中自带的数据集）123456# load datairis = load_iris()df = pd.DataFrame(iris.data, columns=iris.feature_names)df['label'] = iris.targetdf.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']df.label.value_counts() 2 50 1 50 0 50 Name: label, dtype: int64 选取两个特征sepal length和sepal width，绘制散点图12345plt.scatter(df[:50]['sepal length'], df[:50]['sepal width'], label='0')plt.scatter(df[50:100]['sepal length'], df[50:100]['sepal width'], label='1')plt.xlabel('sepal length')plt.ylabel('sepal width')plt.legend() &lt;matplotlib.legend.Legend at 0x1b17e936160&gt; 数据处理：将pandas类型数据转换为np.array123data = np.array(df.iloc[:100, [0, 1, -1]])X, y = data[:, :-1], data[:, -1]y = np.array([1 if i == 1. else -1 for i in y]) 定义模型12345678910111213141516171819class Model(): def __init__(self): self.w = np.ones(len(data[0])-1, dtype=np.float32) self.b = 0 self.l_rate = 0.1 def linear_func(self, w, b, x): return np.dot(x, w) + b def fit(self, X_train, y_train): finished = False while not finished: wrong_count = 0 for d in range(len(X_train)): if y_train[d] * self.linear_func(self.w, self.b, X_train[d]) &lt;= 0: self.w = self.w + self.l_rate * y_train[d] * X_train[d] self.b = self.b + self.l_rate * y_train[d] wrong_count += 1 if wrong_count == 0: finished = True return "perceptron model" 1234perceptron = Model()perceptron.fit(X, y)print(perceptron.w)print(perceptron.b) [ 7.8 -10. ] -12.099999999999973 使用自己训练的模型做二分类1234567x_points = np.linspace(4, 7, 10)y_ = -(perceptron.w[0] * x_points + perceptron.b) / perceptron.w[1]plt.plot(x_points, y_)plt.plot(data[:50, 0], data[:50, 1], 'bo', color='blue', label='0')plt.plot(data[50:100, 0], data[50:100, 1], 'bo', color='orange', label='1')plt.legend() &lt;matplotlib.legend.Legend at 0x1b17ecb4d68&gt; 使用sklearn中自带的感知机模型123456from sklearn.linear_model import Perceptronclf = Perceptron(fit_intercept=False, max_iter=1000, shuffle=False)clf.fit(X, y)print(clf.coef_)print(clf.intercept_) [[ 74.6 -127.2]] [0.] c:\python36\lib\site-packages\sklearn\linear_model\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning. FutureWarning) 绘制sklearn训练得到的感知机模型1234567x_points = np.arange(4, 8)y_ = -(clf.coef_[0][0] * x_points + clf.intercept_) / clf.coef_[0][1]plt.plot(x_points, y_)plt.plot(data[:50, 0], data[:50, 1], 'bo', color='blue', label='0')plt.plot(data[50:100, 0], data[50:100, 1], 'bo', color='orange', label='1')plt.legend() &lt;matplotlib.legend.Legend at 0x1b17f046278&gt; C:\Python36\Lib\site-packages\sklearn\datasets\data]]></content>
  </entry>
  <entry>
    <title><![CDATA[python中如何批量修改文件后缀名]]></title>
    <url>%2F2019%2F07%2F05%2Fpython%E4%B8%AD%E5%A6%82%E4%BD%95%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E5%90%8E%E7%BC%80%E5%90%8D%2F</url>
    <content type="text"><![CDATA[需求背景win10中的锁屏壁纸着实好看，想着能不能在本机中找到壁纸存放的目录，于是网上搜了一下，还真有。 壁纸文件存放的目录是1C:\Users\18856\AppData\Local\Packages\MicrosoftWindowsContentDeliveryManager_cw5n1h2txyewy\LocalState\Assets 上面18856是我电脑上的账户名，只需要修改为你自己的账户名即可，其它的所有分级目录都相同。 切换到噶目录下后，发现所有文件都没有后缀名，不能直接用图片查看器打开，需要一个个修改后缀名为.jpg格式，但是手工是在是太麻烦，因此想着用Python批量修改。 实现用os.path里面几个常用的API可以实现需求。 代码123456789101112131415161718192021222324import osimport syspath_input = sys.argv[1]ext_input = sys.argv[2]components = path_input.split('\\')path_new = ''# 将原始单斜杠'\'转为双斜杠'\\'for idx, item in enumerate(components): if idx != (len(components) - 1): path_new += item + '\\\\' else: path_new += item# print(path_new)files = os.listdir(path_new)for file in files: # 分隔文件名和后缀名 fullname = os.path.splitext(file) newname = fullname[0] + ext_input os.rename(path_new + '\\\\' + file, path_new + '\\\\' + newname) 运行从命令行中运行，需要附带两个参数： 原文件所在的目录，将windows中文件资源管理器上的路径拷贝过来； 目标后缀名，如.jpg 运行示例12python batch_rename.py C:\Users\18856\AppData\Local\Packages\Microsoft.Windows.ContentDeliveryManager_cw5n1h2txyewy\LocalState\Assets .jpg 参考文章 https://www.runoob.com/python/att-string-split.html https://www.cnblogs.com/wuxie1989/p/5623435.html https://blog.csdn.net/weixin_40449300/article/details/83184928]]></content>
  </entry>
  <entry>
    <title><![CDATA[安装jupyter notebook和修改字体]]></title>
    <url>%2F2019%2F07%2F02%2F%E5%AE%89%E8%A3%85jupyter-notebook%E5%92%8C%E4%BF%AE%E6%94%B9%E5%AD%97%E4%BD%93%2F</url>
    <content type="text"><![CDATA[安装 jupyter notebookjupyter notebook 有两种方式安装：一种是通过 Anaconda，Anaconda里面已经集成了jupyter notebook；另一种是通过pip install安装，本文中我采用的是第二种安装方法。 我Windows系统中只安装了Python3，因此控制台中输入python就指向Python3，如果系统中Python2和Python3共存，那么在控制台中可能需要输入python3，因为官方建议在Python3下面安装jupyter notebook。 在控制台中输入下面命令安装jupyter notebook:12python -m pip install --upgrade pippython -m pip install jupyter 安装需要花一定时间，等成功之后，在控制台输入:1jupyter notebook 启动jupyter notebook。然后选择一个目录，点击new就可以新建Python文件了。 配置 jupyter notebook 主题和字体这里首先需要安装一个第三方包jupyter-themes:1pip install jupyterthemes github仓库中有每个参数（包括主题、字体、字体大小等）的详细介绍和如何配置，如果有需要可以耐心研究研究。 下面这个配置可以比较好的满足需求。1jt -t oceans16 -f fira -fs 13 -cellw 90% -ofs 11 -dfs 11 -T 直接在控制台中输入上述命令，接着重新启动jupyter notebook就可以更新设置了。 最后的效果是这样的： 参考文章 https://blog.csdn.net/qq_30565883/article/details/79444750 https://jupyter.org/install.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何删除github仓库中某个文件或者文件夹]]></title>
    <url>%2F2019%2F06%2F04%2F%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4github%E4%BB%93%E5%BA%93%E4%B8%AD%E6%9F%90%E4%B8%AA%E6%96%87%E4%BB%B6%E6%88%96%E8%80%85%E6%96%87%E4%BB%B6%E5%A4%B9%2F</url>
    <content type="text"><![CDATA[从远处clone仓库到本地在本地任意找一个文件夹，鼠标右键打开git bash，将远程仓库clone到此文件夹下面。1git clone &lt;仓库的git地址&gt; 进入到仓库目录中1cd &lt;仓库名&gt; 删除文件夹如果文件夹名称是单独的英文单词，不带有空格，那么输入：1git rm -r &lt;文件夹名&gt; 如果文件夹名称是中文名或者带有多个英文单词但是使用空格分隔，那么输入1git rm -r &apos;&lt;文件夹名&gt;&apos; # 同前面的区别是多了单引号，可以使用tab补全文件夹名称 删除文件如果只是删除某个特定文件的话：1git rm &lt;文件名全程&gt; # 包含文件名+后缀 如果需要批量删除某类后缀名的文件1git rm *.&lt;后缀名&gt; # e.g. git rm *.md 将修改提交到远程仓库123git add *git commit -m &quot;输入提示信息&quot;git push origin master 搞定！]]></content>
  </entry>
  <entry>
    <title><![CDATA[HelloWorld of Keras]]></title>
    <url>%2F2019%2F05%2F17%2FHelloWorld-of-Keras%2F</url>
    <content type="text"><![CDATA[mnist_cnn1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# -*- coding: utf8 -*-# "Hello World" of Keras in image classification taskfrom __future__ import print_function # 在Python2的代码中可以使用Python3的print函数，即需要加上括号import kerasfrom keras.datasets import mnistfrom keras.models import Sequential # 序列模型，可以封装各种网络层: 卷积层、池化层、全连接层、dropout等from keras.layers import Dense, Dropout, Flattenfrom keras.layers import Conv2D, MaxPooling2Dfrom keras import backend as K # Keras是一个高层API，后端使用TensorFlow或者Theanobatch_size = 128num_classes = 10epochs = 12 # 12个epoch足够训练好模型img_rows, img_cols = 28, 28 # mnist dataset中image的大小# 如果第一次跑，会通过url方式从amazon下载mnist.npz；如果已经下载过了，那么直接加载本地mnist.npz(x_train, y_train), (x_test, y_test) = mnist.load_data()# 根据不同的后端，将图片转换为不同的格式，TensorFlow是channel_lastif K.image_data_format() == 'channels_first': x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) # 通道为1 x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) input_shape = (1, img_rows, img_cols)else: x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) input_shape = (img_rows, img_cols, 1)# 将每个pixel的类型从integer转为float32，使除法计算更加精确x_train = x_train.astype('float32')x_test = x_test.astype('float32')# 将0-255范围的pixel值转化到0-1x_train /= 255x_test /= 255# 如果后端是TensorFlowprint('x_train shape:', x_train.shape) # 输出(60000, 28, 28, 1)print(x_train.shape[0], 'train samples') # 输出60000print(x_test.shape[0], 'test samples') # 输出10000# 每个y_train或者y_test本来是一个整数表示每一类，现转换为one-hot encodingy_train = keras.utils.to_categorical(y_train, num_classes)y_test = keras.utils.to_categorical(y_test, num_classes)# 实例化一个序列模型model = Sequential()# Conv1model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))# Conv2model.add(Conv2D(64, (3, 3), activation='relu'))# Pool1model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Dropout(0.5))# 将maxpooling后的64个activation map 全部拉伸为一个向量model.add(Flatten())model.add(Dense(128, activation='relu'))model.add(Dropout(0.5))# 用softmax函数将logits转为每个类别的概率model.add(Dense(10, activation='softmax'))# 设置损失函数，优化器，度量标准model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])# 训练模型# verbose=1 展示详细的训练过程# verbose=0 只显示最后结果，不展示过程# verbose=2 每个epoch输出一条信息，不展示详细的训练过程# validation_data会在每个每个epoch结束后计算当前模型的准确率，validation_data不参与训练model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=2, validation_data=(x_test, y_test))# 在测试集上测试模型效果score = model.evaluate(x_test, y_test, verbose=0)print('Test loss:', score[0])print('Test Accuracy:', score[1]) 训练过程123456789101112131415161718192021222324252627282930313233x_train shape: (60000, 28, 28, 1)60000 train samples10000 test samplesTrain on 60000 samples, validate on 10000 samplesEpoch 1/12 - 248s - loss: 0.2778 - acc: 0.9140 - val_loss: 0.0612 - val_acc: 0.9800Epoch 2/12 - 219s - loss: 0.0982 - acc: 0.9708 - val_loss: 0.0433 - val_acc: 0.9857Epoch 3/12 - 212s - loss: 0.0766 - acc: 0.9776 - val_loss: 0.0354 - val_acc: 0.9876Epoch 4/12 - 226s - loss: 0.0653 - acc: 0.9806 - val_loss: 0.0342 - val_acc: 0.9879Epoch 5/12 - 221s - loss: 0.0573 - acc: 0.9828 - val_loss: 0.0307 - val_acc: 0.9896Epoch 6/12 - 230s - loss: 0.0539 - acc: 0.9834 - val_loss: 0.0286 - val_acc: 0.9907Epoch 7/12 - 224s - loss: 0.0490 - acc: 0.9850 - val_loss: 0.0280 - val_acc: 0.9901Epoch 8/12 - 229s - loss: 0.0475 - acc: 0.9856 - val_loss: 0.0300 - val_acc: 0.9904Epoch 9/12 - 249s - loss: 0.0465 - acc: 0.9862 - val_loss: 0.0286 - val_acc: 0.9906Epoch 10/12 - 257s - loss: 0.0423 - acc: 0.9866 - val_loss: 0.0261 - val_acc: 0.9910Epoch 11/12 - 243s - loss: 0.0393 - acc: 0.9883 - val_loss: 0.0313 - val_acc: 0.9903Epoch 12/12 - 277s - loss: 0.0413 - acc: 0.9877 - val_loss: 0.0266 - val_acc: 0.9907Test loss: 0.026646837043244158Test Accuracy: 0.9907Process finished with exit code 0 如果是第一次运行，会从 https://s3.amazonaws.com/img-datasets/mnist.npz 下载数据集，Windows会存放在c://Users//&lt;User name&gt;//.keras/datasets下面；Linux会存放在home/.keras/datasets下面。 cifar10_cnn.py12 训练过程 参考 Keras Model API: https://keras.io/models/model/ mnist_cnn.py: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py cifar10_cnn.py: https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py https://www.cnblogs.com/lfri/p/10485597.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[李学龙老师在2017届本科生毕业典礼上的讲话]]></title>
    <url>%2F2019%2F05%2F04%2F%E6%9D%8E%E5%AD%A6%E9%BE%99%E8%80%81%E5%B8%88%E5%9C%A82017%E5%B1%8A%E6%9C%AC%E7%A7%91%E7%94%9F%E6%AF%95%E4%B8%9A%E5%85%B8%E7%A4%BC%E4%B8%8A%E7%9A%84%E8%AE%B2%E8%AF%9D%2F</url>
    <content type="text"><![CDATA[演讲原文尊敬的各位老师、各位家长，各位师弟、师妹们： 大家早上好！ 我想汇报和分享的很多故事其实都是“曾经”，但是我今天更想用“这一年”来说。曾经有一首歌叫《同桌的你》，曾经有一部电影叫《大话西游》，曾经有一本书叫《未来之路》，曾经在这一年我到了合肥。大约坐了将近40个小时的火车，其实完全可以加上一个注释：怀抱着光荣、梦想、期望、憧憬，但其实对我来说，当时旅途就是旅途本身，至多是一种坚持，至少当时我是这么认为的。在这一年，在北方长大的我，第一次见到了竹子，它顽强地在并不富饶的土地上茁壮成长；在这一年很多来自南方的同学，他们第一次见到了水在极端情况下的迸发和绽放。1994年的漫天大雪里，我现在还能记得很多穿着单衣的同学在欢呼雀跃。 这一年，我18岁之前建立的所有自信心都被打碎了，荡然无存，如樯橹灰飞烟灭，因为在我曾经自诩很擅长的每一个方面都有N多的人比我强。当我跟他们一样穿着拖鞋、端着饭盆去食堂的时候，总会有人说“看！这是国奥金牌，这也是国奥金牌，这是某个省的状元，这又是某个省的状元。”其实给人压力最大的并不是你知道有人比你优秀，而是你每天都要和他们在一起；也不是说你觉得比你优秀的人比你更努力，而是你发现其实他们不太努力的时候还是比你优秀。在这一年，很幸运的，我跟他们一样有了一个让我终生引以为傲、倍加珍惜的名字——科大人！ 科大人很拼，江湖传言“穷清华，富北大，不要命的上科大”。但科大就是科大，科大有自己的秉持、自己的传统、自己的文化、自己的理念，我们其实没有必要去跟别人去比。科大人很萌，像“天使路”、“勤奋路”这样的名字，如果不是情商和智商的终极极品爆发大概是想不到的。科大人很执着，1995年毕建忠（9304/9315校友）和我分别任校学生会东西区体育部长的时候，我们（重新）启动了“巾帼杯”女子足球赛，听说一直踢了二十几年，到现在还有。科大人很团结，这个不需要多说，等大家到新的学习和工作岗位上，大家自然会知道，我保证。其实科大人还有很多共同的禀赋和标签，刚才蒋书记和校长也都提到了，像“红专并进，理实交融”其实已经融进了科大人的血脉，已经刻入了科大人立德树人的骨髓。 我是早上三点半的航班到的合肥，我当时在想跟大家讲点什么呢？其实我想了讲“知道，不知道，知不道，道不知”的故事，或者给大家讲“知足，不知足，知不足”的故事。后来想了想，还是不讲这些了。因为我的资历和经历也比较有限，很多故事也是听别人讲的。所以在毕业典礼的时候，我想给大家讲两个我会对毕业生说的我的担心吧。 首先，我担心大家会以为社会上和大学里是一样的。其实我们看一下大学，从中国古代的太学到西方古典模式的大学到中西方现代模式的大学，大学始终是这么一个存在，它鼓励我们去弘扬我们的品德、砥砺我们的品格、开拓我们的视野、激发我们的潜力，让我们不断地完善和更新，达到一种更好的自我，趋于完美和完善的境地。虽然大学的入门门槛在不断地调整，但大学始终是一个象牙塔，它是社会少数精英阶层的消费。但是当我们迈向社会的时候，我们会发现，盖人生历程，大抵逆境居十之六七，顺境亦居十之三四，而顺逆两境又常相间，我们会碰到很多的困难。为什么呢？因为社会对年轻人的宽容和忍让、理解和支持同大学是不一样的。“物可瞬间无主，人须时时有心”，我们能保证不变初心，在我们的追求和志向不被外物所改变的情况下，我建议大家学会适应。达尔文在《物种起源》里说，得以生存的不见得是最强大的，也不见得是最智慧的，但一定是最适合环境的。唯一不变的事情就是变化本身，所以我送给大家的第一个词是“适应”，并请大家记住，适应绝不是随波逐流。 第二个担心是，我担心大家认为课本里学到的知识可以让大家出去生活，至少是生存了，因为生活和生存是两个概念。其实课本里的知识如果是完备的话，我们没有必要去建立一所实体大学。事实上课本里的知识、大家学过的知识很可能是不完备的，不齐整的，甚至可能是不正确的。以光学为例，我有两个透镜，有一个光轴，这边有个蜡烛，这边有个屏，蜡烛成什么样的像，这个我们可以在课本中学到，但是你在做一个实际系统的时候，这两个透镜能严格地同轴吗？或许不能！这个时候该怎么解决，课本里似乎不会告诉你。那么学电的话，我们学电子管、晶体管，并不表示我们要去用它，我们是要知道历史上发生过什么样的事情，我们应该怎么样去学习，我们要学习“学习的本领”，我们去归纳总结，去提炼升华。其实，科学研究本身至少有两个目的。第一个目的是实际的应用，去解决实际的问题。我们理工科的学生，尤其应该如此，绝对不能纸上谈兵。那么另一个目的就是满足人类对世界的好奇心。我们知道在电口（电学）上很著名的故事。当法拉第发现电磁感应定律的时候，他并不知道能做什么；麦克斯韦预言电磁波存在的时候，法拉第刚刚去世；当赫兹证明电磁波存在的时候，麦克斯韦又刚刚去世；当马可尼开始进行无线通讯的时候，赫兹也去世了。但是我们不能忘记科学史上这一步一步好奇心的驱使。其实能够鼓励创新的年代并不是特别的多，我们常说“千里马常有，而伯乐不常有”。我们看一看在欧洲，从后希腊到罗马到文艺复兴，其实创新沉睡了一千年。在中国我们有卷帙浩繁的经史子集，我们几乎可以从中间找到现在的任何一个发现或发明的原始的雏形，但是我们必须要承认，我们的技术是多于科学的，我们没有能够把炼丹术发展成化学，没有能够把观星术发展成天文学。所以在今天，在全国、全社会鼓励创新驱动发展的时候，我想大家还是非常幸运的。所以我想送给大家第二个词是“好奇”，而且好奇绝不是随心所欲。 我个人并不是特别推崇“人情练达即文章”，但是我坚信“世事洞明皆学问”。我想在大学的五年里（现在是四年制），大家至少学会了一个人的时候怎么样去平静、去思考，两个人的时候怎么样去合作、去争论，三个人的时候如何去协调、去平衡。其实我们担心的事情还很多，我们担心大家有成绩的时候妄自尊大，担心大家碰到困难的时候妄自菲薄。正因为大家很优秀，所以我们的担心才很多。 15年前的毕业典礼，我是博士生的毕业代表，到现在我还记得当时我的发言，我说“春来几度，苍翠依旧，于无声处，却已见茁壮。而今我们将成为科大的历史，但母校永远是我们心中的一座丰碑，上面镌刻着老师的关爱、同学的友情，和我们的点点滴滴……”很快大家就要离开这个校园，可能还会离开这个城市，或许很多人可能还会短期或长期离开我们的祖国，但是我深信大家或早或晚一定会回来！我是毕业6年之后回到合肥，我没有去会场，我直接打车到了黄山路的一个小饭店，进去之后，老板一句不经意的问候“很久没见了”，让我“泪飞顿作倾盆雨”，刚才在我们的校旗传过来的过程中，我心里就是这样的感觉。 我想大家一定会记得这一年，虽然这一年以后也会成为曾经，但是大家一定会记得在这一年大家收获了母校、老师、师兄师姐们的一些不可辜负的爱和期望。如果每一位科大人都是一颗闪亮的星，那么我们希望以一颗颗星的光芒去引领整个星河璀璨、瀚海星云的梦想。谢谢大家！ 演讲视频 李学龙(946)校友在2017届本科生毕业典礼上的讲话(节选)]]></content>
      <tags>
        <tag>李学龙</tag>
        <tag>演讲</tag>
        <tag>科大</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[佛祖.py]]></title>
    <url>%2F2019%2F05%2F04%2F%E4%BD%9B%E7%A5%96-py%2F</url>
    <content type="text"><![CDATA[皮一下哈哈… 代码123456789101112131415161718192021222324252627282930print(" _ooOoo_ ")print(" o8888888o ")print(" 88 . 88 ")print(" (| -_- |) ")print(" O\\ = /O ")print(" ____/`---'\\____ ")print(" . ' \\| |// `. ")print(" / \\||| : |||// \\ ")print(" / _||||| -:- |||||- \\ ")print(" | | \\\\\\ - /// | | ")print(" | \\_| ''\\---/'' | | ")print(" \\ .-\\__ `-` ___/-. / ")print(" ___`. .' /--.--\\ `. . __ ")print(" ."" '&lt; `.___\\_&lt;|&gt;_/___.' &gt;'"". ")print(" | | : `- \\`.;`\\ _ /`;.`/ - ` : | | ")print(" \\ \\ `-. \\_ __\\ /__ _/ .-` / / ")print(" ======`-.____`-.___\\_____/___.-`____.-'====== ")print(" `=---=' ")print(" ")print(" ............................................. ")print(" 佛祖镇楼 BUG辟易 ")print(" 佛曰: ")print(" 写字楼里写字间，写字间里程序员； ")print(" 程序人员写程序，又拿程序换酒钱。 ")print(" 酒醒只在网上坐，酒醉还来网下眠； ")print(" 酒醉酒醒日复日，网上网下年复年。 ")print(" 但愿老死电脑间，不愿鞠躬老板前； ")print(" 奔驰宝马贵者趣，公交自行程序员。 ")print(" 别人笑我忒疯癫，我笑自己命太贱； ")print(" 不见满街漂亮妹，哪个归得程序员？") 打印效果：]]></content>
  </entry>
  <entry>
    <title><![CDATA[写出pythonic的代码]]></title>
    <url>%2F2019%2F05%2F04%2F%E5%86%99%E5%87%BApythonic%E7%9A%84%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[列表遍历Pythonic1234names = ['juntao', 'xiaojun', 'mingming', 'haohao']# 查找名字列表中带有字母'm'的名字m_name = [name for name in names if 'm' in name]print(m_name) 不要用循环写！12345m_name = []for name in names: if 'm' in name: m_name.append(name)print(m_name) 字典遍历Pythonic1234exam_detail = &#123;'juntao': 44, 'xiaojun': 88, 'mingming': 99, 'haohao': 22&#125;# 找出及格的学生及其分数score_greater_than_60 = &#123;k: v for k, v in exam_detail.items() if v &gt;= 60&#125;print(score_greater_than_60) 不要这样写！12345score_greater_than_60 = &#123;&#125;for k, v in exam_detail.items(): if v &gt;= 60: score_greater_than_60[k] = vprint(score_greater_than_60) 参考文章 一些 pythonic 的代码实例：https://github.com/mikeckennedy/write-pythonic-code-demos https://blog.csdn.net/g8433373/article/details/80709116]]></content>
  </entry>
  <entry>
    <title><![CDATA[一些Python语法]]></title>
    <url>%2F2019%2F05%2F01%2F%E4%B8%80%E4%BA%9BPython%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[关键字 globalglobal关键字主要目的是为了在函数中使用全局变量。1234567891011121314count = 10def modify_count(): temp_count = 20 print('local variable: ', temp_count) global count print('global variable: ', count) count = 100 print('after modified: ', count) returnprint('before modify_count(): ', count)modify_count()print('after modify_count(): ', count) 输入结果：1234567before modify_count(): 10local variable: 20global variable: 10after modified: 100after modify_count(): 100Process finished with exit code 0 从代码中可以看到，，如果要在函数modify_count()中使用全局变量count，那么需要使用global关键字修饰。同时，函数内部对count的修改，将影响到函数外面count的值。 if __name__ == &#39;__main__&#39; 说明因为在 Python 中，一个.py文件就是一个模块，模块中一般写了很多函数供其他模块使用。但我们需要测试模块中函数的正确性，这时候就需要用到 if __name__ == &#39;__main__&#39;. __name__是每个模块的一个属性名，如果我们需要在当前模块中编写测试代码，一般情况下，我们是将测试代码放在 if __name__ == &#39;__main__&#39;这条判断语句下面，因为如果是直接运行当前模块，那么__name__的值就是__main__，条件判断下面的测试代码将会被执行。 如果有另外一个模块module_2.py引用了当前模块module_1.py,那么当我们运行module_2.py时，module_1.py中的__name__的值将变成module_2，即引用了module_1这个模块的模块名。那这时module_1中的if判断将不满足，也就不会执行测试代码，module_2也就只是导入了module_1中的函数，符合我们的期望。 np.random.seed()说明seed(int) 接收一个整数做为生成随机数的算法的参数。如果接收到的整数值相同，那么产生的随机数也相同。 代码123456import numpy as npnum = 0while num &lt; 5: np.random.seed(5) print(np.random.random()) num += 1 输出结果123450.221993171089739480.221993171089739480.221993171089739480.221993171089739480.22199317108973948 但是设置的seed()的值只生效一次，下次使用random()函数如果不是上次的seed()值，那么将会产生不同的随机数。 代码123456import numpy as npnum = 0np.random.seed(5)while num &lt; 5: print(np.random.random()) num += 1 输出结果123450.221993171089739480.87073230617737640.206719155339426420.91861090793792160.48841118879482914 从结果可以看到，第一次输出的random()值，由于和上面代码一样设置了seed(5)，所以第一行结果相同；但是后面4次循环由于没有继续设置seed()，因而产生的随机数不同。]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pycharm在需要输入命令行参数时如何调试]]></title>
    <url>%2F2019%2F04%2F30%2Fpycharm%E5%9C%A8%E9%9C%80%E8%A6%81%E8%BE%93%E5%85%A5%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0%E6%97%B6%E5%A6%82%E4%BD%95%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[1. 前言在 pycharm 中进行调试，一般的做法是：先设置断点，然后开始调试程序。调试过程中选择step over, step into, step out, resume program等操作。 但是当程序需要从命令行中读取参数时，该怎么调试呢？ 如果和之前一样，设置断点，然后开始调试，但在这种做法下，程序没有从命令行中获取到参数；如果在 pycharm 的 teminal中输入 python xxx.py -x xx -y yy -z zz，这种做法会直接运行完程序，无法在断点处停下来。 2. 解决方法在 pycharm 中选择 Run -&gt; edit configurations，然后在parameters中填入需要设置的命令行参数，这时候不需要输入python xxx.py。点击apply然后OK。 然后在代码中就可以直接 debug 了，会在断点处停下来。 参考文章 https://blog.csdn.net/wishchin/article/details/78560725]]></content>
  </entry>
  <entry>
    <title><![CDATA[pycharm调试]]></title>
    <url>%2F2019%2F04%2F29%2Fpycharm%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[pycharm中调试功能按钮说明列表 竖排 Resume Program(F9): 运行到下一个断点。 横排 step into(F7)和step into my code(Shift+Alt+F7之间的区别：前者会进入到一些系统函数内容，后者只会进入自己定义的函数内部。 参考文章 pycharm调试功能]]></content>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下使用virtualenv新建一个python3虚拟环境]]></title>
    <url>%2F2019%2F04%2F28%2Fubuntu%E4%B8%8B%E4%BD%BF%E7%94%A8virtualenv%E6%96%B0%E5%BB%BA%E4%B8%80%E4%B8%AApython3%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[1. 虚拟环境的意义因为不同的应用需要的环境可能是不同的，比方说A和B程序都需要用到第三方库C，但是A只能在C(version=1.0)下面运行，B只能在C(version=2.0)下面运行，这时要想同时运行A和B程序就会存在问题。 虚拟环境提供的好处就是，可以将不同应用程序所需要的环境隔离开来，每个程序有一套属于自己专属的环境，程序之间不会相互干扰。 2. 步骤 首先需要安装 virtualenv 1sudo apt-get install python-virtualenv 接着创建 python3 的虚拟环境(ubuntu中默认安装了python2和python3) 1234cd ~/1997tanjuntao/ # 切换到一个目录下面virtualenv -p /usr/bin/python3 py3env # 在当前目录下面创建新目录py3env(目录名可以自定义)，py3env中就是虚拟环境# 如果是新建一个python2环境，可以这样做# virtualenv -p /usr/bin/python2 py2env 接着激活环境 切换到py3env所在目录1cd ~/1997tanjuntao/ source命令激活虚拟环境1source py3env/bin/activate 这时候会发现命令行前面多了一个括号 (py3env) 这个新建的虚拟环境中使用的是python3，默认情况下，没有包含系统python3中安装的包，很干净。 这时候使用pip install安装的第三方包，只存在于这个虚拟环境中，不会影响系统中的python3 退出虚拟环境1deactivate # 一句话 参考文章 https://blog.csdn.net/qingche456/article/details/65465760]]></content>
  </entry>
  <entry>
    <title><![CDATA[解决hexo中发布文章后图片无法显示的问题]]></title>
    <url>%2F2019%2F04%2F28%2F%E8%A7%A3%E5%86%B3hexo%E4%B8%AD%E5%8F%91%E5%B8%83%E6%96%87%E7%AB%A0%E5%90%8E%E5%9B%BE%E7%89%87%E6%97%A0%E6%B3%95%E6%98%BE%E7%A4%BA%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1. 问题描述默认情况下，在 hexo 中新建一篇markdown博文，在文章中插入本地图片，再部署到 github 上面，是无法显示这些图片的。 2. 解决方法首先找到博客根目录下面的_config.yml文件，修改post_assrt_folder的值为true. 接着 git bash 切换到博客根目录下面，安装第三方插件hexo-assrt-image1npm install hexo-assrt-image --save 接着hexo new &quot;文章名&quot; 新建一篇文章，会发现source/_posts/目录下面会生成一个和 markdown 文件同名的文件夹。再将当前这篇文章中需要插入的图片放到这个文件夹中，再到 markdown 中引用该文件夹中的图片，最后hexo g -&gt; hexo d，就可以正常的查看这些图片了。 参考文章 https://blog.csdn.net/qq_38148394/article/details/79997971 https://www.jianshu.com/p/3db6a61d3782]]></content>
  </entry>
  <entry>
    <title><![CDATA[解决pycharm在同目录下import，pycharm会报错，但实际可以正常运行的错误]]></title>
    <url>%2F2019%2F04%2F28%2F%E8%A7%A3%E5%86%B3pycharm%E5%9C%A8%E5%90%8C%E7%9B%AE%E5%BD%95%E4%B8%8Bimport%EF%BC%8Cpycharm%E4%BC%9A%E6%8A%A5%E9%94%99%EF%BC%8C%E4%BD%86%E5%AE%9E%E9%99%85%E5%8F%AF%E4%BB%A5%E6%AD%A3%E5%B8%B8%E8%BF%90%E8%A1%8C%E7%9A%84%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[1. 问题描述假如我们的目录结构是这样： 项目名称是HelloWorld，在项目主目录下面新建一个文件夹test_dir，接着在HelloWorld/test_dir目录下面新建两个文件: HelloWorld/test_dir/hello1.py和HelloWorld/test_dir/hello2.py。 hello1.py中插入如下代码：1234import hello2 as h2print(h2.hello_world())print(h2.nihao()) hello2.py中插入如下代码：12345def nihao(): return 'nihao'def hello_world(): return 'hello world' 此时，会发现在hello1.py中一直红线提示No module named hello2： 但是如果我们运行hello.py发现是能够正常输出结果的。 2. 解决方法在左侧工程目录树中，选中test_dir，右键，然后选择 Mark directory as，再选择source root，然后就会发现先前的红线错误提示已经没有了。 3. More…如果我们是在当前工程主目录下面新建两个文件HelloWorld/hello1.py和HelloWorld/hello2.py，两个.py文件的代码内容和之前一样，这时候却又不会出现No module named hello2这种错误了。 参考文章 https://www.zhihu.com/question/52880389/answer/134369870]]></content>
  </entry>
  <entry>
    <title><![CDATA[论论文笔记: Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning]]></title>
    <url>%2F2019%2F04%2F18%2F%E8%AE%BA%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-Manipulating-Machine-Learning-Poisoning-Attacks-and-Countermeasures-for-Regression-Learning%2F</url>
    <content type="text"><![CDATA[这篇文章发表于 2018 年，是第一篇针对线性回归模型提出投毒攻击方法的论文，实验证明：这种gradient-based的攻击方法效果很好；同时这篇文章里面也提出了一种防御方法：TRIM，实验结果也证明其防御效果很好。 主要贡献 第一篇针对linear regression进行poisoning attack的论文，之前的论文都是针对classification的模型 改造了一个原本针对分类问题进行投毒攻击的模型，将其应用在回归问题中，将攻击结果作为一个baseline 提出了一种基于数据集统计特征的攻击方法，只需要掌握有限的信息即可完成攻击 提出了防御算法TRIM,能够抵御众多的攻击，效果比传统的robust statistic好 方法Linear Regression Model传统的线性回归模型：$$\mathcal{L}\left(\mathcal{D}{\mathrm{tr}}, \boldsymbol{\theta}\right)=\underbrace{\frac{1}{n} \sum{i=1}^{n}\left(f\left(\boldsymbol{x}{i}, \boldsymbol{\theta}\right)-y{i}\right)^{2}}{\operatorname{MSE}\left(\mathcal{D}{\text { tr }}, \boldsymbol{\theta}\right)}+\lambda \Omega(\boldsymbol{w})$$ 根据$\Omega(w)$的不同，linear regression 可以分为下面4种 类型 $\Omega(w)$ Ordinary Least Square(OLS) $\Omega(w) = 0$ Ridge $\Omega(\boldsymbol{w})=\frac{1}{2}\ \boldsymbol{w}\ _{2}^{2}$ LASSO $\Omega(\boldsymbol{w}) = \ {w}_1\ $ Elastic-Net Regression $\Omega(w) = \rho\ w_1\ + (1-\rho)\frac{1}{2}\ w_2^2\ $ Adversarial Model这里定义敌手模型。 敌手模型主要是用来对潜在用户进行分析建模，例如：假设攻击者掌握了多少知识、攻击者的目标是什么、攻击者的攻击策略是什么等。具体的可以从下面4个维度来对潜在的攻击者进行建模： 维度 描述 Adversary Goal 一般包含两种:availability attack &amp; integrity attack.前者主要目的是使整个模型的可用性降低，后者主要是使模型在针对特定样本做 inference 时，准确率降低 Adversary Knowledge 一般包含两种：white-box &amp; black-box. 对于前者，假设攻击者知晓：traning data &amp; learning algorithm &amp; loss function &amp; model parameters；对于后者，假设攻击者只知晓：learning algorithm &amp; loss function。但是这篇文章中，作者通过产生替代数据，同样可以得到 model parameters. Adversary Capability 攻击者的能力，一般定义为其能往数据集中插入多少 poisoning samples. $n:original \ samples$, $p :poisoning \ samples$, $N = n + p:\ total \ smaples$, 定义poisoning rate $\alpha = p/n$ Adversary Strategy $\begin{array}{rl}{\arg \max {\mathcal{D}{p}}} &amp; {\mathcal{W}\left(\mathcal{D}^{\prime}, \boldsymbol{\theta}{p}^{\star}\right)} \ {\text { s.t. }} &amp; {\boldsymbol{\theta}{p}^{\star} \in \arg \min {\boldsymbol{\theta}} \mathcal{L}\left(\mathcal{D}{\mathrm{tr}} \cup \mathcal{D}_{p}, \boldsymbol{\theta}\right)}\end{array}$ 攻击者的目标主要是优化上面的目标函数：即如何插入 poisoning samples 来使得在 $D’$上的 loss 值最大. 攻击方法攻击者的目标函数：$$\begin{array}{rl}{\arg \max {\mathcal{D}{p}}} &amp; {\mathcal{W}\left(\mathcal{D}^{\prime}, \boldsymbol{\theta}{p}^{\star}\right)} \ {\text { s.t. }} &amp; {\boldsymbol{\theta}{p}^{\star} \in \arg \min {\boldsymbol{\theta}} \mathcal{L}\left(\mathcal{D}{\mathrm{tr}} \cup \mathcal{D}_{p}, \boldsymbol{\theta}\right)}\end{array}$$ 注： 目标函数 $W$一般用 validation set 上面的 loss 来表示。loss 越大，表名攻击效果越好。对于 linear regression, loss function = Mean Square Error(MSE) 那么该插入什么样的 poisoning sample 才能使目标函数 $W$ 的值最大呢？ 答案是：考虑梯度，考虑$W$对$D_p$的梯度。有了这个梯度，我们就能使用gradient ascent方法来更新$D_p$，直到最后$W$收敛，我们可以得到最佳的$D_p$. 但是这个优化问题是一个Bi-level问题，即约束条件本身也是一个优化问题，解决这种问题通常情况下是NP-hard.因为$x_c$和$W$并不是显示相关，而是通过$\theta$间接相关，因此作者通过chain rule来计算所需要的梯度 $\nabla_{\boldsymbol{x}_{c}} \mathcal{W}$: $$\nabla_{\boldsymbol{x}{c}} \mathcal{W}=\nabla{\boldsymbol{x}{c}} \boldsymbol{\theta}\left(\boldsymbol{x}{c}\right)^{\top} \cdot \nabla_{\boldsymbol{\theta}} \mathcal{W}$$ 注：$x_c$表示 poisoning sample 的 features 1. 首先求解公式的第二项 $\nabla_{\theta} \mathcal{W}$ 第二项比较好计算，因为在线性回归问题中，目标函数表示的是在 validation set 上计算到的 loss： $$\mathcal{W}{\mathrm{val}}\left(\mathcal{D}{\mathrm{val}}, \boldsymbol{\theta}\right)=\frac{1}{m} \sum_{j=1}^{m}\left(f\left(\boldsymbol{x}{j}^{\prime}, \boldsymbol{\theta}\right)-y{j}^{\prime}\right)^{2}$$ 对这个函数求对$\theta$的偏导：$$\nabla_{\boldsymbol{\theta}} \mathcal{W}{\mathrm{val}}=\left[ \begin{array}{c}{\nabla{\boldsymbol{w}} \mathcal{W}{\mathrm{val}}} \ {\nabla{b} \mathcal{W}{\mathrm{val}}}\end{array}\right]=\left[ \begin{array}{c}{\frac{2}{m} \sum{j=1}^{m}\left(f\left(\boldsymbol{x}{j}\right)-y{j}\right) \boldsymbol{x}{j}} \ {\frac{2}{m} \sum{j=1}^{m}\left(f\left(\boldsymbol{x}{j}\right)-y{j}\right)}\end{array}\right]$$ 至此，公式第二项偏导数计算完毕，下面计算第一项。 2. 求解公式第二项 $\nabla_{\boldsymbol{x}{c}} \boldsymbol{\theta}\left(\boldsymbol{x}{c}\right)^{\top}$ 防御方法实验结果]]></content>
  </entry>
  <entry>
    <title><![CDATA[SSH公钥方式登录原理以及对称加密和非对称加密知识点总结]]></title>
    <url>%2F2019%2F04%2F10%2FSSH%E5%85%AC%E9%92%A5%E6%96%B9%E5%BC%8F%E7%99%BB%E5%BD%95%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E5%92%8C%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[先占坑，后面需要学习这块的内容，用博客记录下来，加深理解！ 参考文章 https://blog.csdn.net/csm201314/article/details/78453579]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统中常见目录的含义及作用]]></title>
    <url>%2F2019%2F04%2F02%2FLinux-%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9B%AE%E5%BD%95%E7%9A%84%E5%90%AB%E4%B9%89%E5%8F%8A%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言这篇博客将随着我对 Linux 系统的不断使用和了解而不定期更新。 常用目录的含义 目录 含义 /bin 存放 linux 中常用命令，如cd pwd ls等 /lib /etc /var 参考文章 http://blog.sina.com.cn/s/blog_684d52a90102uw30.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[安装固态硬盘]]></title>
    <url>%2F2019%2F04%2F02%2F%E5%AE%89%E8%A3%85%E5%9B%BA%E6%80%81%E7%A1%AC%E7%9B%98%2F</url>
    <content type="text"><![CDATA[0.前言以下全是个人的装机经验，没有很认真的写，只是打算做个记录，这样下次如果还需要干这类活时有个参考。不建议follow！！仅供一点参考。 笔记本老早就出现各种问题了，觉得应该是系统的问题而不是硬件的问题，于是寻思着重装一下系统。但是心里对重装系统有些抵触，因为会导致很多之前辛苦安装好配置好的软件无法使用。拖了好久，终于买了一块固态硬盘来重装系统…笔记本简直焕发第二春啊！ 1. 数据备份 为了避免发生意外情况，建议还是首先把原先硬盘中重要的文件备份一下。所谓备份，就是把一些重要的文件拷贝到另外一块存储介质中，如移动硬盘等，这样重装系统能够放心点。 其实需要备份的文件感觉不是很多，个人觉得下面这些需要着重备份： C盘：桌面，图片，视频。偷懒一点，就把user文件夹全部备份一下，因为这个差不多是系统盘中最重要的文件了。 其它：如果是数据盘，那不用考虑，所有的文件都得备份。如果是软件盘，那么之前一些工程文件目录，如eclipse，webstorm，pycharm等，做好备份。另外Tim，微信聊天记录也最好备份一下，这样重装之后可以直接导入这些记录。 2. 制作启动U盘因为打算把新系统装到 SSD 中，所以需要事先制作一个启动 U 盘，用来安装新系统。 下载系统iso镜像 可以使用微软官方的渠道下载，直接搜索windows10镜像下载 微软，然后下载一个工具，让其将Windows操作提供写入到U盘中(U盘会被格式化，事先备份U盘) 也可以使用第三方的镜像，比较推荐的是 MSDN我告诉你。找到打算下载的镜像，将完整的ed2k地址复制到迅雷等下载工具中，启动镜像下载。 制作启动U盘 可以使用UltraISO rufus等启动U盘制作工具，导入之前下载的iso镜像，就可以轻松完成U盘制作。 3. 拆机拆机过程中不用太担心，小心操作，一般不会带来什么问题的。拆机之前记得先把笔记本电源取下来，防止意外发生。 将笔记本后盖中所有看得见的螺丝全部拧下来，然后将笔记本后盖和主板分离。这个过程中需要留意一点，因为主板上面有可能有线和后盖通过一个卡口连在一块，所以在取下后盖之前，需要将这个卡口解开，不能直接就分离后盖。 找到硬盘位。拧下所有的螺丝，将原来的 HDD 取下，装上新的 SSD，按照相反的步骤再装回原位，这样新的固态硬盘就轻松的装好了。 找到光驱位。拧下所有的螺丝，将原来的 HDD 装入光驱位硬盘托架(需花钱额外购买)，记得一定要将 HDD 装到位，也就是一定要保证接线口是完全缝合的，否则可能在装好新系统后，无法读取到这块 HDD 硬盘。 将原来光驱的前挡板取下来，装到这块硬盘托架上，这样能够保证托架装上笔记本后，不会明显的凹下去，因为如果使用硬盘托架厂商送的通用挡板，会导致笔记本装好后没有一体性，因为光驱位那里凹下去了，影响美观。 将后盖装回去(有线的地方先把线接好)，再将所有的螺丝全部拧回去，这样就完成了拆机安装 SSD 的过程。 4. 重装系统到 SSD目标是将新系统装到 SSD 中，原来的 HDD 作为普通的硬盘使用。 具体的，笔记本开机后，不断按f2 f8 delete(不同笔记本不同)进入BIOS。找到boot，选择从U盘启动。 这时候会识别到刚才新装的固态硬盘，会提示是否需要进行分区，因为SSD一般是128G或者256G，感觉没有必要再分区了，整块盘作为一个分区就可以了。然后接下来就是愉悦的安装过程了，这个比较傻瓜，没什么好说的。 5. 可能的问题 新系统中无法使用触控板。可以卸载当前的触控板驱动，然后去笔记本厂商官网，找到当前这款型号笔记本对应的触控板驱动程序，重新安装就可以了。 读取不到光驱位硬盘。可以搜索一下这个问题，一般会提示让下载一个amd xxx controller，然后打开设备管理器，将驱动程序手动更新一下就可以了。 原先的光驱挡板不好拆卸。实在不行就暴力拆卸，装到托架上时，用502胶水粘一下。]]></content>
  </entry>
  <entry>
    <title><![CDATA[常用的正则匹配]]></title>
    <url>%2F2019%2F04%2F02%2F%E5%B8%B8%E7%94%A8%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[正则表达式由两个部分组成：1/正则表达式主体/修饰符(可选) 其中修饰符主要用到两种： i: ignore 的意思。表示忽略大小写进行匹配。 g: global 的意思。表示匹配整个字符串，否则第一次匹配成功后，不会继续匹配后面的字符串。 常用的特殊字符 特殊字符 含义 * 0个或者 N 个 + 1个或者 N 个 ? 0个或者1个 .等价[^\n\r] 匹配任意字符(除了换行和回车) \ 可以做转义字符也可以和\b等一起使用表示特殊含义 ^ 匹配输入的开始如/^A/匹配一个以字符A开头的字符串 $ 匹配输入的结束如/t$/匹配一个以字符t结尾的字符串 [0-9] 匹配一个数字 \d 同上匹配一个数字 \s 空白字符(空格、制表符、换行符等) \D等价[^0-9] 匹配一个非数字字符 [a-zA-Z] 匹配任何一个大小写字母 \w 匹配一个单字字符(字符、数字、下划线) \W 同上匹配一个非单字字符 [^xyz] 匹配不包含xyz字符的第一个字符 使用正则表达式的常用方法 方法 描述 replace() 查找匹配的字符串，然后用新字符串替代 split() 将原字符串按照正则表达式拆分，将结果存入到一个数组中 使用括号的子字符串匹配 这种情况下，会将匹配的结果存入到一个数组中，也就是会 记忆 匹配得到的结果。 几个例子 eg1 1234var re = /\w+\s/g;var str = "fee fi fo fum";var myarr = str.match(re);console.log(myarr); 输出结果1["fee+空格", "fi+空格", "fo+空格"] eg2(综合性实例) 1234567891011121314151617181920212223// names中不同名字之间有多个空白字符、制表符等不可见字符var names = "Harry Trump ;Fred Barney; Helen Rigby ; Bill Abel ; Chris Hand ";console.log("===========original string==============\n" + names);var pattern = /\s*;\s*/;var namelist = names.split(pattern);// console.log(namelist);// 将匹配到的结果存起来作为$1和$2var newpattern = /(\w+)\s+(\w+)/;newnamelist = [];for (var i = 0, len = namelist.length; i &lt; len; i++) &#123; // 名字颠倒 newnamelist[i] = namelist[i].replace(newpattern, "$2, $1");&#125;console.log(newnamelist);// 按照字母表排序newnamelist.sort();console.log(newnamelist); 需要注意的就是函数split()和replace()的使用。 如果是带有括号的，那么匹配的结果将存放在$1 $2 … $n中]]></content>
  </entry>
  <entry>
    <title><![CDATA[Office 2016 激活方法]]></title>
    <url>%2F2019%2F04%2F02%2FOffice-2016-%E6%BF%80%E6%B4%BB%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[激活方法 下载安装激活工具：链接: https://pan.baidu.com/s/1C3KqB4m7dnm9t2uKoDARHw 提取码: 9r4h Windows 10 中可能会提示说下载的文件中包含病毒，导致下载不成功。这时候只需要在Windows defender中找到刚才那条阻止记录，并将其设置为允许，重新下载文件，就可以下载成功了。 接下来执行压缩包里面的.exe文件，安装到最后，Windows defender又提示说检测到病毒xxx不能执行，安装失败之类的，这时候需要在windows安全中心，选择管理设置，然后关闭实时保护，然后以管理员方式运行压缩包里面的.bat文件，再重新安装刚才那个.exe文件，这时候就可以成功安装了，安装完之后再开启实时保护。 启动软件，点击红色按钮，在打开 office 中的账户，发现已经激活成功了，简直神器！ 参考文章 https://blog.csdn.net/weixin_40941966/article/details/80872533]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python3: ModuleNotFoundError: No module named 'PIL']]></title>
    <url>%2F2019%2F04%2F02%2FPython3-ModuleNotFoundError-No-module-named-PIL%2F</url>
    <content type="text"><![CDATA[问题使用matplotlib.pyplot模块调用绘图函数时，出现以上错误。 解决方法在控制台中输入如下命令1pip install pillow 即可解决问题]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用 Github Pages + Hexo 搭建一个个人博客]]></title>
    <url>%2F2019%2F04%2F02%2F%E4%BD%BF%E7%94%A8-Github-Pages-Hexo-%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[前言其实在很早之前，曾使用 WordPress 搭建过一个个人博客。当时也是满满的激情，想模仿大佬们学着写技术博客。但是后来由于忙着追求GPA，加上自身懒惰自控力不行，博客就基本放弃更新了。 但是现在已经过上了研究生生活，每天有大把的时间可以由自己来支配，同时接触的东西也越来越多：做项目需要实时的学习一些技术和技巧，需要不断总结下来；各种学术报告会，听完之后需要回去再认真揣摩消化，变成自己的东西，这也需要总结下来。虽然之前也零零散散的做了一些笔记，但是组织松散不方便查找，遂考虑重新开通个人博客，将平常生活中的所学所思都记录下来，做技术和科研的积淀，争取能够厚积薄发！ 开始搭建 1. 前期准备 安装node.js：因为hexo是一个基于node.js开发的静态博客框架，其运行必须要有node.js环境支持 安装git：要往 github 提交代码，就必须先在本地安装好 git 客户端 在 github 上面新建一个仓库，名称设为你的github账户名.github.io 上面软件的安装应该没有大问题，去官网下载一路 next 基本就可以了。需要注意的是，如果之前没有用过 git 提交代码到 github，那么第一次安装 git 之后还需要做些 SSH Key 的设置，这里不打算赘述这个步骤。 2. 安装hexo打开 git bash，直接输入下面这条命令：1npm install -g hexo-cli 安装可能需要几分钟，耐心等待，不出意外的话，能够成功安装 hexo 3. 构建本地目录在本地文件系统中，任意找一个目录作为网站文件的存放目录，比如在 D盘 新建一个目录blog，作为网站所有文件存放的根目录。 在 git bash 中进入这个目录12cd d:cd blog/ 下载安装 hexo 博客系统所需要的各种文件1npm install 安装过程可能比较慢，且没有进度条提示。安装完之后，在blog目录下面会产生很多新的目录，简单解释一下几个常用目录和文件的含义及作用 themes：存放所有的博客主题，hexo 默认安装的主题是 landscape source: 存放所有的 markdown 源文件。所有新建的博文(post) 都存放在source/_posts/ 这个目录下面。如果后面新建了其它页面，比如关于，归档，标签等，那么在source目录下面将会新产生about, achieve, tag等目录。 public：这个目录中存放所有的网页文件，html,css, javascirpt等等。简单说，hexo 会将我们编写的 markdown 文件解析成 html 文件，同时配套生成一些 css 样式文件，进而保护 markdown 源文件不被其他人获取。 _config.yml：全局的配置文件，可以配置网站 标题, 子标题 等 4. 启动前面安装步骤顺利完成之后，就可以在本地启动 hexo 了。 1npm server # 或者是 npm s, 效果等价 这时会提示说在localhost:4000端口可以访问刚刚建立的博客，正常情况下，如果4000端口没有被占用的话，那么就可以正常访问到博客，会有一篇默认的Hello World的博文。如果4000端口被占用了，具体的表现就是网站打不开，那么可以尝试更换一个启动端口，具体命令可以自行搜索。 5. 部署到 Github Page在部署到 github page之前，需要在本地修改一些配置。 首先打开_config.yml，搜索deploy字段，修改为如下格式：123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:tanjuntao/tanjuntao.github.io.git branch: master 其中第二个repo字段的值，需要改为你在 github 上面那个网站项目对应的 SSH 值，也不打算截图介绍这个 SSH 值是怎么获取到的了。需要注意的是每个:后面需要紧跟一个空格，否则会出错！ 接着，在 git bash 中执行下面的命令：1npm install hexo-deployer-git --save 执行这条命令可能会出错，解决办法是 npm + flush刷新一下缓存, 具体的命令记不清楚。 最后就可以 deploy 到远程的 github 上面了。 1hexo deploy # 或者 hexo d, 效果是一样的 这时候，就可以看到 github 仓库里面生成了很多文件，但是找不到 source 文件夹，这就是前面介绍到的，保护了源文件。 要通过github账户名.github.io方式访问网站，还需要在项目仓库中的setting中设置中找到github page，设置一下后，才能够访问到。 6. 使用后面当需要新建一篇博文时，只需要做下面三个步骤，非常方便！1234hexo new &quot;博文标题&quot;hexo generate # hexo ghexo server # hexo s, 启动本地服务，可在本地中预览效果，这步可选hexo deploy # hexo d 7. 修改主题hexo 中默认使用的主题是landscape,但最为流行的一个主题叫next，打算安装next主题的可以接着往下看。 首先切换到博客更目录下面，也就是前面的blog/目录，执行下面命令：1git clone https://github.com/iissnan/hexo-theme-next themes/next 可能需要一段时间才能完成。 接着打开跟目录下面的_config.yml文件，修改theme字段的值为next就可以了。 如果后期打算更换其它主题，只需要修改这个theme的值就可以了，同样非常方便！ next主题默认的样式还是没有符合我的要求：左边有一个导航栏，且有关于 分类 标签 这些选项，我们还需要进一步对主题进行设置。 在/theme/next/目录中找到_config.yml文件，同样是一个设置文件，只不过仅仅是next这个主题的设置文件。 搜索Scheme，修改其值为Pisces或者Gemini，因为只有这两个 scheme 能显示左右侧边栏。 12345# Schemes# scheme: Muse# scheme: Mist# scheme: Piscesscheme: Gemini 接着搜索sidebar，参考下列注释进行设置：12345678910111213141516sidebar:# Sidebar Position - 侧栏位置（只对Pisces | Gemini两种风格有效） position: left //靠左放置 #position: right //靠右放置# Sidebar Display - 侧栏显示时机（只对Muse | Mist两种风格有效） #display: post //默认行为，在文章页面（拥有目录列表）时显示 display: always //在所有页面中都显示 #display: hide //在所有页面中都隐藏（可以手动展开） #display: remove //完全移除 offset: 12 //文章间距（只对Pisces | Gemini两种风格有效） b2t: false //返回顶部按钮（只对Pisces | Gemini两种风格有效） scrollpercent: true //返回顶部按钮的百分比 其它一些设置，包括头像，新页面，评论系统等，可以参见Hexo的Next主题详细配置 这篇文章，非常详细！ 8.其它关于使用 hexo deploy时，如何附带像git commit那样的message，只需要如下命令即可：1hexo deploy --message &quot;提交的信息内容&quot; 非常方便！ 9.注意事项 不要修改使用hexo new命令生成的文章标题 在编辑hexo new生成的 markdown 文件时，不要动手修改title的值，否则会导致这篇post无法显示在网站上！ 10. 如何配置 NexT 主题可以参考下面链接： NexT 官方提供的主题配置 hexo 的 NexT 主题详细配置 这篇文章就先到这里啦~ 主要参考 https://segmentfault.com/q/1010000007139908 https://www.jianshu.com/p/3a05351a37dc https://www.jianshu.com/p/40e4349a0cc7]]></content>
  </entry>
  <entry>
    <title><![CDATA[测试博文]]></title>
    <url>%2F2019%2F04%2F01%2F%E6%B5%8B%E8%AF%95%E5%8D%9A%E6%96%87%2F</url>
    <content type="text"><![CDATA[二级标题：测试markdown语法的支持情况 有序列表 有序列表 无序列表 无序列表 这里是引用内容 123import tensorflow as tfimport numpy as npprint('hello world') 这是行内代码，这是加粗，这是斜体]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F31%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
